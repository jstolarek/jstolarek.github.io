<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"
    xmlns:dc="http://purl.org/dc/elements/1.1/">
    <channel>
        <title>Yet Another Lambda Blog</title>
        <link>https://jstolarek.github.io</link>
        <description><![CDATA[A language that doesn't affect the way you think about programming, is not worth knowing]]></description>
        <atom:link href="https://jstolarek.github.io/feed.xml" rel="self"
                   type="application/rss+xml" />
        <lastBuildDate>Sat, 17 Jan 2026 00:00:00 UT</lastBuildDate>
        <item>
    <title>My Top 5 games of 2025</title>
    <link>https://jstolarek.github.io/posts/2026-01-17-my-top-5-games-of-2025.html</link>
    <description><![CDATA[<article>
    <section class="header">
        Posted on 17/01/2026
    </section>
    <section>
        <h1 id="my-top-5-games-of-2025">My Top 5 games of 2025</h1>
<p>In 2025, I managed to spend quite a substantial amount of time on gaming. I had
an ambitious plan of writing longer reviews of games that I finish. That didn’t
work out as intended and the only game I reviewed in 2025 was <a href="2025-04-19-the-legend-of-heroes-trails-in-the-sky-fc-game-review.html"><em>The Legend of
Heroes: Trails in the Sky
FC</em></a>.
This post is an attempt to make up for it. Here’s a list of my top 5 games
finished this year, with a brief overview of each one. Games are listed in the
order of playing.</p>
<h2 id="breath-of-fire-iv">Breath of Fire IV</h2>
<p><em>Breath of Fire is</em> a series of JRPGs that was somewhat popular in the 90s
(first instalment released on SNES in 1993) and early 2000s (fifth instalment on
PS2 in 2003)<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>. <em>Breath of Fire IV</em> was released for the first PlayStation in
2000<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>. This was late in the console’s life cycle. As a result the game is
well polished when it comes to technical aspects and stands out in terms of
graphics. It features large, well animated and detailed 2D sprites, seamlessly
combined with 3D environments. And while these environments can be rotated,
they still look like they were 2D pixel art.</p>
<p>To me, the most important aspect of <em>Breath of Fire IV</em> is its cinematic
storytelling, with a unique approach of presenting the plot both from the
perspective of the main protagonist (Ryu) as well as the antagonist (Fou-Lu) -
the game regularly switches between the two, until their paths finally converge
towards the end of the game. Perhaps it isn’t as impressive by today’s
standards, but it certainly was a standout 25 years ago.</p>
<div class="thumbnail">
<figure>
<a href="/images/posts/2026-01-17-my-top-5-games-of-2025/bof4_crt.jpg"><img src="/images/posts/2026-01-17-my-top-5-games-of-2025/bof4_crt_thumbnail.jpg" /></a>
</figure>
<figcaption>
I experimented with CRT photography while playing Breath of Fire IV.
Most attempts were unsuccessful. This is one of the better photos, but you can still
see shift towards green colour in certain areas.
</figcaption>
</div>
<p>If I were to point out any downsides, it would be the fights. These occur
randomly, though not very frequently. I mean, not very frequently by 90s JRPG
standards. Fights are turn-based. First, you select attacks for three of your
characters; you can swap between characters in the front and back row, somewhat
similar to what <em>Final Fantasy X</em> would offer a year later. Once you commit to
actions for the given turn, attacks play out according to initiative. At this
point you basically just watch a series of attack animations. Despite nice
visuals, this gets boring.</p>
<p>Another thing I didn’t exactly like is the fact that Ryu is a <em>silent
protagonist</em>, i.e. he does not speak a single world throughout the game. The
rationale behind the silent protagonist trope is that the protagonist is an
avatar of the player; rather than having game creators insert words into the
player’s mouth, the player can insert their own thoughts instead. This is not
an uncommon plot device in JRPGs - other titles such as the <em>Persona</em> series,
<em>Chrono Trigger</em> or <em>Fire Emblem Awakening</em> immediately come to mind - but I
have never found this rationale to be convincing. Rather than increasing
immersion - which, I believe, is the ultimate goal here - it creates a main
character that is an empty, unmemorable, and uninspired vessel. This does not
mean that the game with a silent protagonist has to be bad, though. I mean,
<em>Chrono Trigger</em> and <em>Persona</em> are consider among the best JRPGs ever made,
despite having a silent protagonist, and <em>Breath of Fire IV</em> is also very good.
It’s just that nobody is going to remember the game for its protagonist.</p>
<h2 id="persona-5-royal">Persona 5 Royal</h2>
<p>I was planning to write a long, separate post on <em>Persona 5 Royal</em> (P5R), but
that is less and less likely to happen. This short recap will have to suffice,
at least for now.</p>
<p>I first started playing <em>Persona 5 Royal</em> in late 2023. After playing for about
17 hours or so, I lost momentum and put down the game for a couple of weeks. I
resumed playing around March 2024 and my playthrough was going smoothly until I
ran into problems with Proton, which just <a href="https://github.com/ValveSoftware/Proton/issues/7894">stopped working on my Linux
machine</a>. Despite being
fairly knowledgeable with Linux and Wine, after weeks of debugging I had to
admit defeat. This is the exact kind of problem I highlighted in <a href="posts/2023-11-27-proton-is-detrimental-to-linux-as-a-gaming-platform.html">my critique
of Proton from late
2023</a>:</p>
<blockquote>
<p>A lot of games do not run well, or at all, with Proton. Moreover, even if a
game runs fine on the release, there is absolutely no guarantee that it will
stay this way. In the past, there have been many situations when changes
introduced in a game patch or Proton broke a game.</p>
</blockquote>
<p>I have then put down the game for nearly a year, and only resumed playing in
early 2025, when I decided to bite the bullet and boot into Windows to play.</p>
<p><em>Persona 4 Golden</em> (P4G) is one of the best JRPGs I have ever played and it set
the bar high for <em>Persona 5 Royal</em>. In some aspects, P5R is an improvement; in
some, it is not. The gameplay definitely feels better, thanks to the addition
of a whole bunch of new combat mechanics that make dungeon crawling a lot more
fun. Also, unlike in P4G, the dungeons are no longer randomly generated. Where
P5R falls short in my opinion, is its plot. The initial third of the game,
roughly 40 hours or so, just feels kinda <em>meh</em>. (And yes, you read that right -
the game takes around 120h to complete.) The plot seems a bit forced, without a
clear goal, and even characters themselves admit they don’t know what to do.
Only later in the game, things start to converge and make more sense, and the
resolution of the plot feels satisfying.</p>
<div class="thumbnail">
<figure>
<a href="/images/posts/2026-01-17-my-top-5-games-of-2025/p5r_lessons.jpg"><img src="/images/posts/2026-01-17-my-top-5-games-of-2025/p5r_lessons_thumbnail.jpg" /></a>
</figure>
<figcaption>
I know I shouldn’t be the one pointing at others for poor English
usage, this but lesson here many seem to have skipped in real life.
</figcaption>
</div>
<div class="thumbnail">
<figure>
<a href="/images/posts/2026-01-17-my-top-5-games-of-2025/p5r_fight.jpg"><img src="/images/posts/2026-01-17-my-top-5-games-of-2025/p5r_fight_thumbnail.jpg" /></a>
</figure>
<figcaption>
P5R combines elements of a life sim with dungeon crawling.
</figcaption>
</div>
<p>I have one major complaint about the <em>Persona 5 Royal</em>. The game spans over the
course of three schools semesters. The first two semesters you experience
day-by-day, spending mornings in school and afternoons on free activities. In
the original <em>Persona 5</em> released in 2016, the third semester has a handful of
scripted events and most of the days are skipped. The <em>Royal</em> version released
in 2019, expands on the third semester, adding a whole plot arc, a new dungeon,
and new characters, whose plot arcs are fully resolved during that third
semester. However, to access this new version of the third semester you must
spend your time with Maruki, the school counsellor, and max out your social link
with him. The game doesn’t say this explicitly though. Since Maruki was not
among my favourite characters, I didn’t really spend time with him and only
learned that <strong>I’ve been locked out of the third semester after playing the game
for over 90 hours</strong>. I don’t think any game has ever made me feel that angry
and disappointed. I always thought that <em>Persona</em> games are great examples of
being beginner-friendly, not allowing the players to play themselves into a
corner or do something really stupid. But the Maruki thing is one huge
exception to that. I ended up downloading save files from the Internet. This
allowed me to experience the plot first-hand, rather than watching a playthrough
on YouTube, but not being able to play with characters that I have built was
nevertheless a huge disappointment. Online search quickly reveals that I am not
the only person who experienced the same problem. But despite the third
semester issue and the initial plot not being well-motivated, I still consider
<em>Persona 5 Royal</em> as one of the best JRPGs I have ever played.</p>
<div class="thumbnail">
<figure>
<a href="/images/posts/2026-01-17-my-top-5-games-of-2025/p5r_velvet_room.jpg"><img src="/images/posts/2026-01-17-my-top-5-games-of-2025/p5r_velvet_room_thumbnail.jpg" /></a>
</figure>
<figcaption>
Velvet Room is a recurring location in Persona series, though it
looks slightly different each time.
</figcaption>
</div>
<h2 id="final-fantasy-vii-rebirth">Final Fantasy VII Rebirth</h2>
<p>For many Western players, myself included, <em>Final Fantasy VII</em> was the first
JRPG they have ever played. A recent remake of this cult classic has been
controversial since it makes departures from the original, possibly the biggest
of which is splitting the original story into three consecutive games.
<em>Rebirth</em> is the second, and latest, instalment in the trilogy.</p>
<p>Having read the reviews first, I approached <em>Final Fantasy VII Rebirth</em> with a
certain caution. A consistent complaint about <em>Rebirth</em> was the amount of
mini-games the player has to participate in. Gameplay bloat was already a
problem for me in the <em>Final Fantasy VII Remake</em>, i.e. the first entry in the
new trilogy. I mean, <em>Remake</em> takes around 30h to complete if you just focus on
the main plot, and it corresponds to a 5-hour segment in the original game.
Obviously, a lot had to be added to make the game longer. This was my main
gripe with the <em>Remake</em>.</p>
<div class="thumbnail">
<figure>
<a href="/images/posts/2026-01-17-my-top-5-games-of-2025/ff7r_map.jpg"><img src="/images/posts/2026-01-17-my-top-5-games-of-2025/ff7r_map_thumbnail.jpg" /></a>
</figure>
<figcaption>
Most of the activities on the world map are boring and repetitive.
</figcaption>
</div>
<p>With <em>Rebirth</em>, I wanted to focus on the story, just like I did in the <em>Remake</em>,
so I ignored most of the activities and side quest in the open world, as these
tend to be very generic and uninspired. That being said, the world is beautiful
and wandering without a purpose on a chocobo is fun, albeit not very rewarding.</p>
<div class="thumbnail">
<figure>
<a href="/images/posts/2026-01-17-my-top-5-games-of-2025/ff7r_cinematic.jpg"><img src="/images/posts/2026-01-17-my-top-5-games-of-2025/ff7r_cinematic_thumbnail.jpg" /></a>
</figure>
<figcaption>
This is the most realistic cinematic I have seen to date.
</figcaption>
</div>
<p>One thing I need to point out about <em>Remake</em> and <em>Rebirth</em> is that I really
don’t like the new real time combat system. I really appreciate turn-based RPGs
and how they force the player to think and plan strategically. In a real-time
system this planning is gone and replaced by hectic button-mashing. In
particular, the remakes have the player control in real-time three (!)
characters. The end result is total chaos; I found the combat system
overwhelming and simply not fun. The nail in the coffin is how camera works, or
rather: how it doesn’t work. Combats often look like this:</p>
<div class="thumbnail">
<figure>
<a href="/images/posts/2026-01-17-my-top-5-games-of-2025/ff7r_fight.jpg"><img src="/images/posts/2026-01-17-my-top-5-games-of-2025/ff7r_fight_thumbnail.jpg" /></a>
</figure>
<figcaption>
Good luck making sense out of this mess.
</figcaption>
</div>
<p>My solution was to set the game difficulty to easy in order to minimize the
amount of time spent in combat. That made the game a lot more enjoyable.</p>
<p>Last, but not least - the plot. As already mentioned, <em>Rebirth</em> makes
departures from the original. I am totally fine with that. Telling the exact
same story twice wouldn’t be much fun for me. I appreciate changes and
additions, except maybe for this weird Roche guy. Both remakes are certainly
slightly weirder than the original, as if it was trying to be a <em>Yakuza</em> game,
but overall I am happy with the plot and the characters.</p>
<p>In the end, after making a conscious effort to avoid the game’s shortcomings,
<em>Final Fantasy VII Rebirth</em> turned out to be a lot of fun.</p>
<div class="thumbnail">
<figure>
<a href="/images/posts/2026-01-17-my-top-5-games-of-2025/ff7r_sephiroth.jpg"><img src="/images/posts/2026-01-17-my-top-5-games-of-2025/ff7r_sephiroth_thumbnail.jpg" /></a>
</figure>
<figcaption>
Sephiroth feels as menacing as he was in the original.
</figcaption>
</div>
<div class="thumbnail">
<figure>
<a href="/images/posts/2026-01-17-my-top-5-games-of-2025/ff7r_girls.jpg"><img src="/images/posts/2026-01-17-my-top-5-games-of-2025/ff7r_girls_thumbnail.jpg" /></a>
</figure>
<figcaption>
Relationship dynamic between Tifa and Aerith feels very much
different and slightly off: they are best friends but at the same time seriously
compete to win Cloud’s heart.
</figcaption>
</div>
<h2 id="unicorn-overlord">Unicorn Overlord</h2>
<p><em>Unicorn Overlord</em> is one of a few recent games where, upon hearing the title
for the first time, you hope it is only a working title that will be changed for
the release. As you can tell, it wasn’t just a working title. But anyway, in
this strategic JRPG you control prince Alain, the rightful heir to the throne
who returns from exile to take back his kingdom from an evil usurper. If the
plot synopsis makes you think that the plot might not be the strongest part of
the game, you will be absolutely right. Luckily, <em>Unicorn Overlord</em> makes up
for it with exceptionally fun gameplay.</p>
<div class="thumbnail">
<figure>
<a href="/images/posts/2026-01-17-my-top-5-games-of-2025/uo_virginia.jpg"><img src="/images/posts/2026-01-17-my-top-5-games-of-2025/uo_virginia_thumbnail.jpg" /></a>
</figure>
<figcaption>
I really appreciate <em>Unicorn Overlord</em> for its 2D art style.
Also, I really got to like Virginia.
</figcaption>
</div>
<p>The game consists of two core elements. Firstly, fighting battles to liberate
new regions. Battles happen in real-time, but there is an active pause. In
<em>Unicorn Overlord</em>, units consist of up to five characters fighting in a single
formation. You don’t get to control individual characters during the battle;
instead battles play out automatically, with characters acting according to
preassigned tactics. Tactics are ordered, conditional lists of attacks, such as
“if there are flying units in front row, attack them with skill X”. With over
60 characters and over 20 basic character classes (and further possibilities of
promoting to advanced classes), the task of figuring out which characters and
tactics result in good synergies is far from trivial. Experimenting with
different builds, unit compositions, and tactics is fun, but also slightly
tiring at times. While the game hints at which character classes are effective
when paired together, the number of available combinations quickly becomes
overwhelming.</p>
<div class="thumbnail">
<figure>
<a href="/images/posts/2026-01-17-my-top-5-games-of-2025/uo_units.jpg"><img src="/images/posts/2026-01-17-my-top-5-games-of-2025/uo_units_thumbnail.jpg" /></a>
</figure>
<figcaption>
Units consist of multiple characters in formation.
</figcaption>
</div>
<div class="thumbnail">
<figure>
<a href="/images/posts/2026-01-17-my-top-5-games-of-2025/uo_tactics.jpg"><img src="/images/posts/2026-01-17-my-top-5-games-of-2025/uo_tactics_thumbnail.jpg" /></a>
</figure>
<figcaption>
Each character has their individual set of tactics.
</figcaption>
</div>
<div class="thumbnail">
<figure>
<a href="/images/posts/2026-01-17-my-top-5-games-of-2025/uo_battle.jpg"><img src="/images/posts/2026-01-17-my-top-5-games-of-2025/uo_battle_thumbnail.jpg" /></a>
</figure>
<figcaption>
Fights between units can be skipped, but watching them play out
really helps in understanding and fine-tuning the tactics.
</figcaption>
</div>
<p>The second core element of gameplay is rebuilding reclaimed areas through
various world map activities, such as gathering resources and using them to
rebuild cities, or carrying out various smaller quests.</p>
<p><em>Unicorn Overlord</em> was much talked about on release due to its English
translation, which takes a lot of liberties w.r.t. the original. Sadly, this
criticism feels justified. Even worse, same concerns can be raised about the
majority of modern English translations from Japanese, <em>Final Fantasy VII
Rebirth</em> being another “great” example.</p>
<p>Overall, I had lots of fun with this game. While the plot isn’t the most
memorable one, <em>Unicorn Overlord</em>’s gameplay feels like a massive improvement
over the <em>Fire Emblem</em> series.</p>
<div class="thumbnail">
<figure>
<a href="/images/posts/2026-01-17-my-top-5-games-of-2025/uo_translation.jpg"><img src="/images/posts/2026-01-17-my-top-5-games-of-2025/uo_translation_thumbnail.jpg" /></a>
</figure>
<figcaption>
Translators went overboard with their effort to make English sound non-casual.
</figcaption>
</div>
<h2 id="pentiment">Pentiment</h2>
<p>Yet another game that I started playing 3 years ago, right after its release in
late 2022, and only finished in 2025. I decided to discard several hours of
past playthrough and start over since I couldn’t recall the plot details.</p>
<p><em>Pentiment</em> takes place in the early XVI century, shortly after the end of
Middle Ages and at the dawn of Renaissance. Big societal changes of that period
paint a backdrop for the main plot, which focuses on the lives of ordinary
people in a fictional Bavarian town of Tassing. Graphically, the game looks
like a 2D adventure of the 90s, but stylized to resemble Middle Ages paintings.
Under the hood though, this is really an RPG. There is no combat or equipment
though. It is the dialogues and choices that drive the game, with various
personal backgrounds and sets of skills available to the main protagonist,
Andreas, affecting what options are available to the player. Perhaps the game
that comes closest in terms of gameplay would be <em>Disco Elysium</em>, though
<em>Pentiment</em> does not have RPG-style checks. Rather, whether you succeed on a
check or not depends solely on the choices you have made so far.</p>
<p>What I loved the most about <em>Pentiment</em> is how it aims to accurately recreate
the daily lives of people in the early XVI century. It shouldn’t come as a
surprise that the director of the game, Josh Sawyer, is a historian by
education; he also happens to be the designer of major RPG hits, such as
<em>Icewind Dale</em>, <em>Neverwinter Nights 2</em>, <em>Fallout: New Vegas</em> and <em>Pillars of
Eternity</em>.</p>
<p><em>Pentiment</em> is an extremely rare case, when I decided to play in Polish, which
brings me to one nitpick that I have about the game. It is pretty evident that
the Polish localization was done solely from the script, since there are many
mistranslations resulting from the lack of dialogue context.</p>
<div class="thumbnail">
<figure>
<a href="/images/posts/2026-01-17-my-top-5-games-of-2025/pentiment_andreas.jpg"><img src="/images/posts/2026-01-17-my-top-5-games-of-2025/pentiment_andreas_thumbnail.jpg" /></a>
</figure>
<figcaption>
Andreas, the main protagonist, has been partially inspired by Albrecht Dürer.
</figcaption>
</div>
<div class="thumbnail">
<figure>
<a href="/images/posts/2026-01-17-my-top-5-games-of-2025/pentiment_dream.jpg"><img src="/images/posts/2026-01-17-my-top-5-games-of-2025/pentiment_dream_thumbnail.jpg" /></a>
</figure>
<figcaption>
Protagonist’s dreams play an important part in the narrative.
</figcaption>
</div>
<h2 id="notable-mentions">Notable mentions</h2>
<p>I also have a few notable mentions; games that didn’t qualify for my top 5, but
are still worth mentioning.</p>
<h3 id="nier-automata">Nier: Automata</h3>
<p>Another game that I managed to complete this year after having started it a few
years ago. I loved the artistic vision - character and world design, music, the
ever-present feeling of longing and solitude - but I found the gameplay lacking.</p>
<h3 id="silksong">Silksong</h3>
<p>I had lots of fun playing Hollow Knight. I am not having so much fun with the
sequel, Silksong, due to its difficulty and how unfair it is at times. I spent
about 20 hours in the game and don’t think I have enough skill to progress past
Act I of the game. At this point, I have pretty much just given up on it.</p>
<h3 id="dispatch">Dispatch</h3>
<p>I am allergic to anything superhero-related. As such, Dispatch comes as a
pleasant surprise, where the story about superheroes is essentially an office
comedy. The game is very light on gameplay and focuses on narrative choices.</p>
<h3 id="doki-doki-literature-club">Doki Doki Literature Club</h3>
<p>I don’t want to spoil this one, so let’s just say this is a kawaii visual novel
with the exact kind of dark twist that I like. Available for free <a href="https://teamsalvato.itch.io/ddlc">on
itch.io</a>, though I played the Switch version.</p>
<h3 id="needy-girl-overdose">Needy Girl Overdose</h3>
<p>Another visual novel with dark twists. This time you assume the role of a
manager for an online streamer, KAngel. It’s up to you whether she’s gonna
spend her time gaming and streaming about nerd stuff, or taking drugs and
indulging in conspiracy theories.</p>
<h2 id="summary">Summary</h2>
<p>Having written this post, two things stand out. Firstly, 2025 was a year of
JRPGs for me. I finished several titles I started a few years back, but also
played a whole bunch of new ones. Secondly, I played a lot - each of my top 5
titles requires dozens of hours - thanks mostly to handheld gaming. Getting the
Nintendo Switch and the Steam Deck is what made the difference for me, but that
is a topic for another post.</p>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr />
<ol>
<li id="fn1"><p>Sixth part of the game was released in 2016 as a free-to-play and was
operational for about a year. Let’s pretend it didn’t happen.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>As I was playing Breath of Fire IV on the original PlayStation, the PC
port from 2003 <a href="https://www.gog.com/en/game/breath_of_fire_iv">was released on
GOG</a>.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

        <p><a href="../blog.html">Back</a></p>
    </section>
</article>
]]></description>
    <pubDate>17/01/2026</pubDate>
    <guid>https://jstolarek.github.io/posts/2026-01-17-my-top-5-games-of-2025.html</guid>
    <dc:creator>Jan Stolarek</dc:creator>
</item>
<item>
    <title>Nix is terrible and I've wasted my life</title>
    <link>https://jstolarek.github.io/posts/2025-06-02-nix-is-terrible-and-ive-wasted-my-life.html</link>
    <description><![CDATA[<article>
    <section class="header">
        Posted on 02/06/2025
    </section>
    <section>
        <h1 id="nix-is-terrible-and-ive-wasted-my-life1">Nix is terrible and I’ve wasted my life<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></h1>
<p><a href="https://github.com/NixOS/nix">Nix</a> is a package manager that derives its basic
principles from functional programming, and has thus gained some traction in the
Haskell community. My first exposure to Nix was 3 years ago, when I was
assigned to work on Haskell projects that used Nix to manage their build
environment and dependencies. Since then, I have met people who are very
enthusiastic about Nix. Unfortunately, <strong>my personal experiences are largely
negative and I find enthusiasm towards Nix unjustified</strong>. In this post, I want
to talk about Nix problems that are swept under the rug by many Nix enthusiasts
and that make Nix a major liability for a programmer.</p>
<h2 id="promising-theory">Promising theory</h2>
<p>Nix can be used either as a package manager, as is done by
<a href="https://nixos.org/">NixOS</a> Linux distribution, or as a build environment and
dependency manager in a programming project. My experience is with the latter,
so I will focus on that<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>. Let’s start by going over the main goals and
(claimed) features of Nix. Let me quote from the project page (bold text not
mine):</p>
<blockquote>
<p><em>Reproducible</em>: Nix builds packages in isolation from each other. This ensures
that they are reproducible and don’t have undeclared dependencies, so <strong>if a
package works on one machine, it will also work on another</strong>.<br />
<em>Declarative</em>: Nix makes it <strong>trivial to share development and build
environments</strong> for your projects, regardless of what programming languages and
tools you’re using.<br />
<em>Reliable</em>: Nix ensures that installing or upgrading one package <strong>cannot
break other packages</strong>. It allows you to <strong>roll back to previous versions</strong>,
and ensures that no package is in an inconsistent state during an upgrade.</p>
</blockquote>
<p>When used as a dependency manager in a project, the main problem Nix attempts to
address is build reproducibility: given a project with Nix configuration, that
project should always build on every machine without requiring any extra
configuration<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>. Nix configuration for a project — referred to as
<em>“derivation”</em> — is written in a declarative language that specifies what
the dependencies are and where to find them, say a GitHub repository under a
specific commit hash. Once a configuration is written, it is possible to launch
Nix shell from inside the project directory. This shell loads all specified
dependencies, both libraries and executables. The project can then be built
inside the Nix shell, and it should always build on every machine, regardless of
the operating system or any other factors.</p>
<p>If you have ever worked on a programming project, the above promises sound like
a dream come true. I mean, no more problems with your code not compiling on
other people’s machines because they have different library versions or because
they are missing the required tools. Who wouldn’t that? Unfortunately, <strong>Nix
demands an exorbitant price for delivering its promises</strong>. I claim that Nix is
a case of the cure being much worse than the disease itself.</p>
<h2 id="sad-reality">Sad reality</h2>
<p>Unfortunately, Nix comes with a whole bundle of issues, that seriously hinder
development.</p>
<p>The first problem with Nix is that it requires a lot of machine resources.
Firstly, disk space. As mentioned in the previous section, Nix installs all the
required project dependencies into a so-called <em>store</em>. As you use Nix, the
store grows in size, since many packages are installed multiple times as part of
different derivations. Nix store on my PC had at one point grown to a whooping
200GB. That’s <em>two hundred gigabytes</em> of libraries. For comparison, my Linux
installation uses 25GB of disk space and includes a full desktop environment, a
suite of various desktop programs (office suite; graphics, sound, and video
editing; dozens of minor tools), and several development toolchains. Nix store
can be purged (<code>nix-collect-garbage</code>) and compacted (<code>nix-store --optimise</code>),
which helps for a while, but it ultimately grows again. Another machine
resource that Nix happily wastes is RAM memory. Every Nix shell I launched in a
project I worked on demanded gigabytes of RAM memory. I need at least two
shells for development, ideally three. On a machine with 16GB of RAM, launching
three Nix shells would result in running out of RAM about 2–3 times a
week. As soon as I started using Nix over three years ago, I had to upgrade to
32GB of RAM. This mostly suffices, but on several occasions even that wasn’t
enough. Such disk and RAM requirements are not justified, since the same
libraries installed via the package manager do not take up some much space and
do not require so much RAM.</p>
<p>The above problems are annoying, but they can be mitigated with money: you can
always buy more disk space and more RAM memory. However, Nix has a much more
fundamental problem. <strong>It wastes the most precious resource, that cannot be
bought for any money: time.</strong> Launching a Nix shell for the first time in a
given project, requires downloading and building dependencies. For projects I
worked on, this typically took several hours. Essentially, a whole day wasted
just to build gigabytes of libraries. Many times I have heard Nix proponents
say, that this problem can be addressed by setting up binary caches. These
apparently should allow skipping local compilation by downloading pre-built
libraries. Despite hearing such claims multiple times, I have never seen such
binary caches set up in a way that mitigates the problem — and below I
will get to the problem of setting anything up with Nix. Unfortunately,
compilation of dependencies is not a one-time thing. Every now and then you
will be rebuilding project dependencies, either because they have changed or
because you garbage-collected your store and the already compiled dependencies
have been removed. <strong>I estimate that waiting for Nix to compile the
dependencies wasted about 7-8 working days every quarter.</strong> To me, this one
thing in itself entirely disqualifies Nix.</p>
<p>Note that with Nix, you will not only waste your time when launching a Nix
shell, but also when switching between git branches that have different Nix
configurations. Each switch to a branch with different configuration means
dependency reload. Such reloads are usually faster than launching the Nix shell
from scratch, but even then calling <code>git status</code> after branch switch can require
a 2–3 minute wait.</p>
<p>Another fundamental problem with Nix is its complexity and the resulting
difficulty of managing a project configuration. When I was first assigned to
work on a project that used Nix, I was determined to learn Nix. I mean, I
should learn how to use the tools required in a project, right? Unfortunately,
despite my best efforts, I never got to a point where I was able to competently
manage the project’s dependencies. Honestly, when I realized, that despite
trying to learn Nix, I am still unable to do basic things with it —
changing a dependency is a basic thing — I felt like I’m just stupid. I
started to ask others for help, and it turned out that this isn’t just me: most
programmers I worked with could not figure out how to manage dependencies with
Nix. Thus, on every single Nix-based project I have been involved with, we had
one or two people who were the “Nix specialists” and whose job was to work on
the Nix configuration whenever it needed to be changed. To me, as a programmer,
this is unacceptable. <strong>We can’t have tools that are so complex, that they
prevent programmers from changing a project’s most basic configuration.</strong></p>
<p>One final complaint is that Nix does not always deliver on its promises. Though
it should guarantee that a project always builds on every machine, I have seen
situations where that was not the case. For example, building Nix dependencies
would fail for someone using a Mac. I am not going to complain about that,
though. For most of the time, Nix builds are reproducible. Even if “for the
most time” is not the same as “always”, problems with Nix fundamentally lie
elsewhere.</p>
<h2 id="cure-worse-than-the-disease">Cure worse than the disease</h2>
<p>I was recently creating a new Haskell project. Some of the dependencies rely on
specialized cryptographic C libraries not widely available on current Linux
distributions. Programmers who want to build my project have to install those
libraries from outside their package manager, and also update some path
variables, such as <code>LD_LIBRARY_PATH</code>. Describing the exact process in a README
took me about 15 minutes. Carrying out those project-specific installation
instructions also shouldn’t take longer than 15 minutes. It might be a slight
annoyance, but it needs to be done <em>once</em>. Project’s dependencies are then
managed via project’s Cabal file in the usual way, so a programmer needs not to
take any extra steps.</p>
<p>Setting up a project in this way is a lot more time efficient than with Nix.
The price of installing dependencies is paid <em>once</em> at the beginning, and it is
a small price. Or who knows, maybe this initial effort will not be small. The
point is: without Nix, you pay the price once. With Nix, you regularly pay a
price that is much higher. The result is that <strong>no other tool in my entire
programming career has wasted so much of my time</strong>. I just cannot afford myself
to use Nix if I want to get things done. And I cannot have project dependencies
managed with a tool that is so complex, it requires dedicated specialists.</p>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr />
<ol>
<li id="fn1"><p>For the lack of ideas, I borrowed the title from <a href="https://www.youtube.com/watch?v=FpNAKDx4CwY">Super Eyepatch
Wolf</a>.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>If you are looking for a more comprehensive coverage of Nix, I highly
recommend <a href="https://www.dgt.is/blog/2025-01-10-nix-death-by-a-thousand-cuts/">Nix - Death by a thousand
cuts</a>.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>Note that Nix <a href="https://linderud.dev/blog/nixos-is-not-reproducible/">does not provide Reproducible
Builds</a>, i.e. it
does not guarantee that a build is always binary-identical.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

        <p><a href="../blog.html">Back</a></p>
    </section>
</article>
]]></description>
    <pubDate>02/06/2025</pubDate>
    <guid>https://jstolarek.github.io/posts/2025-06-02-nix-is-terrible-and-ive-wasted-my-life.html</guid>
    <dc:creator>Jan Stolarek</dc:creator>
</item>
<item>
    <title>Adding a new hard drive to my PC and installing Windows 11 alongside Linux</title>
    <link>https://jstolarek.github.io/posts/2025-05-21-adding-a-new-hard-drive-to-my-pc-and-installing-windows-11-alongside-linux.html</link>
    <description><![CDATA[<article>
    <section class="header">
        Posted on 21/05/2025
    </section>
    <section>
        <h1 id="adding-a-new-hard-drive-to-my-pc-and-installing-windows-11-alongside-linux">Adding a new hard drive to my PC and installing Windows 11 alongside Linux</h1>
<p>I recently ran into a problem that every PC owner eventually faces: running out
of disk space. The amount of free space I had on my partitions was low enough
to be causing trouble every now and then, especially when downloading huge files
from the Internet. I decided to solve the problem by adding a second NVMe drive
to my PC, but I wasn’t sure how this is going to play out when dual booting
Linux and Windows 11. In the end, everything worked the way it should. I want
to document the whole process here, in hope of dismissing misleading information
and FUD found on the Internet.</p>
<h2 id="existing-setup">Existing setup</h2>
<p>My initial partition setup looked like this:</p>
<div class="thumbnail">
<figure>
<a href="/images/posts/2025-05-21-adding-a-new-hard-drive-to-my-pc-and-installing-windows-11-alongside-linux/initial_setup.png"><img src="/images/posts/2025-05-21-adding-a-new-hard-drive-to-my-pc-and-installing-windows-11-alongside-linux/initial_setup.png" /></a>
</figure>
</div>
<p>All partitions are on a single 2TB NVMe drive, containing a dual-boot setup of
Linux and Windows 11. There is a single EFI partition for the bootloaders. For
Linux, I have separate <code>/boot</code> (unencrypted, stores kernel images), <code>/</code>
(encrypted)`, and a dedicated data partition. For Windows, I have two primary
partitions: C:\ drive for the system and D:\ drive for game installations.
Aside from that, there are two special hidden partitions created by Windows and
some leftover unallocated space.</p>
<h2 id="the-plan">The plan</h2>
<p>I decided to get a second 2TB drive — luckily, my motherboard allows
installing two — and use it as a dedicated drive for a new Windows
installation. Then remove all Windows partitions from my first drive and use
reclaimed space to increase the size of Linux data partition. While the plan
was fairly straightforward, there were a couple of unknowns regarding Windows 11
installer’s behaviour in the presence of another drive with existing Linux and
Windows installation. In particular:</p>
<ol type="1">
<li><p>Will the installer use the existing EFI partition, or will it create a new
one on the second drive? In theory, there should only ever be one EFI
partition, so it should re-use the existing one. But if it does, what
happens to the existing Windows bootloader? I wanted to be able to boot
the previous Windows installation until the new one has not been fully
configured.</p></li>
<li><p>What about the hidden Windows partitions? Will the new installation create
its own hidden partitions, or will it reuse existing ones? The latter
might mean that I would not be able to delete these partitions from the
first drive.</p></li>
<li><p>Will the Windows 11 leave existing Linux partitions intact?</p></li>
</ol>
<p>Obviously, the third point was the most important for me. Sure, I have backups,
but losing an existing installation would mean hours of work to restore the
system. That is something I definitely wanted to avoid. I began searching
online and found several discussion threads, where people had similar concerns.
Usually, the advice given was to be on the safe side and remove the Linux drive
for the duration of installation. Once Windows 11 is installed on the new
drive, re-install the Linux drive. Such a procedure would leave me with two EFI
partitions — one on each drive — but it would certainly prevent any
data loss in the installation process. I decided to follow this approach, since
it felt like a safe choice. In hindsight, online advice to remove Linux drive
was FUD — fear, uncertainty, doubt — not backed by facts. But let
me not get ahead of myself.</p>
<h2 id="drive-installation">Drive installation</h2>
<p>The first step was then to temporarily remove the existing drive and install the
new one. Here, I ran into a problem. See these things marked with red arrows
in the photo below?</p>
<div class="thumbnail">
<figure>
<a href="/images/posts/2025-05-21-adding-a-new-hard-drive-to-my-pc-and-installing-windows-11-alongside-linux/thermal_pads.jpg"><img src="/images/posts/2025-05-21-adding-a-new-hard-drive-to-my-pc-and-installing-windows-11-alongside-linux/thermal_pads_thumbnail.jpg" /></a>
</figure>
</div>
<p>The arrow on the right shows a large thermal pad that attaches to the top of the
drive and conducts heat to a radiator. And on the left is a place for
installing a small thermal pad that helps to cool the chipsets at the bottom of
the drive. Both these pads are glued to the drive. When trying to uninstall
the drive, I was able to remove the radiator and to unglue the large thermal pad
at the top. However, small pad at the bottom remained firmly fixed, preventing
removal of the drive from the M.2 slot. Despite applying some considerable
force, the pad would not let go. After a couple attempts I gave up on the idea
of removing it. Damaging the drive physically would equal to losing all data,
whereas Windows 11 installation going wrong was only a potential risk. I
installed the second drive alongside the first one and proceeded to install the
new OS.</p>
<h2 id="windows-11-installation">Windows 11 installation</h2>
<p>Windows installer correctly detected both drives and existing partitions. Of
course, it did not recognize file systems on Linux partitions, but it noticed
that the partitions are there. I picked unallocated space on the new drive as
the target of installation. Before proceeding further, I had to tick a checkbox
that says <em>“I agree everything will be deleted including files, apps, and
settings”</em>. This definitely sounded scary and raised the question: is it only
going to remove data from the target partition, or will it wipe clean the other
partitions as well? I had no other choice but to take a leap of faith here. I
ticked the checkbox and finished the installation.</p>
<p>After rebooting the PC, it turned out that everything worked as expected.
Windows 11 installed on the new drive and created all the required hidden
partitions that it needs. This means I could remove hidden Windows partitions
from the other drive and have that drive entirely used for Linux. Secondly,
Windows 11 correctly detected the existing EFI partition, together with the fact
that there is another Windows installation. GRUB remained untouched, and upon
selecting Windows Boot Manager from the GRUB menu, I was greeted with Windows
bootloader prompting me to select which of the two Windows installation to boot.
This was great news, because it allowed me to use the previous Windows
installation, before I finished setting up the new one. The experience of
choosing which Windows to boot wasn’t entirely smooth though: upon selecting a
Windows installation, my PC would reboot, and only upon selecting Windows Boot
Manager from GRUB again, it would boot into Windows — this time without any
prompting.</p>
<p>Last, but not least, existing Linux partitions remained untouched.</p>
<h2 id="partition-resizing">Partition resizing</h2>
<p>Once I finished setting up the new Windows installation, it was time to remove
old Windows partitions and enlarge my Linux data partition. The task required
changing size of LUKS container, partition inside it, and the file system inside
the partition. I had a lot of questions here and wasn’t entirely sure how to
approach the problem. The only consistent pieces of information I could find on
the Web where that the LUKS container needs to be unlocked in order to be
resized, and that an ext4 file system can be resized online (i.e. while
mounted). After ensuring I have backed up all the data, I decided on “recon by
fire”. I launched <code>gparted</code>, deleted all Windows partitions on the first drive,
and then resized my Linux data partitions using a slider. And it just worked!
The whole process took less than a minute. This is the end result:</p>
<div class="thumbnail">
<figure>
<a href="/images/posts/2025-05-21-adding-a-new-hard-drive-to-my-pc-and-installing-windows-11-alongside-linux/final_partitions.png"><img src="/images/posts/2025-05-21-adding-a-new-hard-drive-to-my-pc-and-installing-windows-11-alongside-linux/final_partitions.png" /></a>
</figure>
</div>
<p>One final finishing touch was required under Windows: update the bootloader so
that it does not show the system from a partition that was just removed. This
was easily achieved using the <code>msconfig</code> Windows tool.</p>
<h2 id="aftermath">Aftermath</h2>
<p>At this point, my goals were achieved. I had Windows 11 installed on a dedicated
2TB drive and my primary data partition on Linux enlarged to 1.76GB. However, I
was in for a couple of surprises. A few days after installing the new drive, I
realized my Samba share on Linux doesn’t work. After a debugging session, I
managed to narrow down the problem to this configuration line in
<code>/etc/samba/smb.conf</code>:</p>
<pre><code>interfaces = lo enp5s0</code></pre>
<p>It specifies the interfaces on which Samba operates: local loopback (<code>lo</code>) and
the Ethernet card (<code>enp5s0</code>). Until a few years back, network interfaces in
Linux had simple names, such as <code>eth0</code> for Ethernet or <code>wlan0</code> for Wi-Fi. But
then systemd introduced something that is called <a href="https://www.freedesktop.org/wiki/Software/systemd/PredictableNetworkInterfaceNames/">Predictable Network Interface
Names</a>
— hence the non-intuitive <code>enp5s0</code> name. Under the above link you will
find rationale for the change as well as a list of good things that this change
does, such as:</p>
<blockquote>
<p>Stable interface names even when hardware is added or removed</p>
</blockquote>
<p>Well, that’s bullshit, because my Ethernet card is now named <code>enp6s0</code>.
The interface name changed with the addition of a new drive, presumably because
drives and Ethernet card reside on the same PCIe bus and the network card now
enumerates differently. As a result, everything that relied on that “stable”
interface name, needs to be updated to the new name. Thank you, systemd.</p>
<p>A second surprise came about two weeks later. For some reason, my Linux could
no longer mount the Windows partition during boot, stalling the boot process
until the default 90 second timeout was reached. It was time for another
debugging session, which revealed that the UUID of the Windows partition
changed. Not only that, the partition reported as being encrypted with
BitLocker. Perhaps unsurprisingly, Windows 11 does things without user’s
knowledge and approval, trying to force them into using BitLocker. It silently
starts encryption of Windows partition some time after system installation,
making the partition unaccessible from outside Windows. Under Windows, system
partition reports as partially encrypted, even though BitLocker is shown as
being disabled. The only solution is to enable BitLocker, let it finish
encrypting the partition, then disable BitLocker and give it time to decrypt the
partition. This allows to access Windows partition from under Linux and have it
mounted during boot without issues.</p>
<h2 id="final-thoughts">Final thoughts</h2>
<p>Overall, the whole process of installing a new drive went smooth. I am
pleasantly surprised that the Windows installer played nicely with existing
Windows and Linux installations. I am also happy with how easy it was to resize
my Linux data partition, without even having to unmount it.</p>

        <p><a href="../blog.html">Back</a></p>
    </section>
</article>
]]></description>
    <pubDate>21/05/2025</pubDate>
    <guid>https://jstolarek.github.io/posts/2025-05-21-adding-a-new-hard-drive-to-my-pc-and-installing-windows-11-alongside-linux.html</guid>
    <dc:creator>Jan Stolarek</dc:creator>
</item>
<item>
    <title>France &#39;40, 2nd Edition. A boardgame review</title>
    <link>https://jstolarek.github.io/posts/2025-04-24-france-40-2nd-edition-a-boardgame-review.html</link>
    <description><![CDATA[<article>
    <section class="header">
        Posted on 26/04/2025
    </section>
    <section>
        <h1 id="france-40-2nd-edition.-a-boardgame-review">France ’40, 2nd Edition. A boardgame review</h1>
<p>Towards the end of 2023 <a href="https://jstolarek.github.io/posts/2023-10-25-salerno-43.html">I reviewed a boardgame called Salerno
’43</a> and mentioned
my return to wargaming. Since then, I have been actively playing wargames
— though maybe not as frequently as I would hope for — and have also
purchased a few new games. The one I want to write about today is <a href="https://www.gmtgames.com/p-635-france-40-2nd-edition.aspx">the second
edition of France ’40 from GMT
Games</a>, which came
out in 2024. I already had the first edition, released in 2013, but this new
release revises the units and the rules. It also offers better quality of
components: thicker counters, sturdier box, and, optionally, a mounted map
— like many other wargames, France ’40 comes with paper maps by default.
Knowing how good the game is, upgrade to the second edition was an obvious
choice.</p>
<div class="thumbnail">
<figure>
<a href="/images/posts/2025-04-24-france-40-2nd-edition-a-boardgame-review/box.jpg"><img src="/images/posts/2025-04-24-france-40-2nd-edition-a-boardgame-review/box_thumbnail.jpg" /></a>
<figcaption>
France ’40 2nd edition box.
</figcaption>
</figure>
</div>
<p>Similarly to Salerno ’43 and other WWII games by Mark Simonitch, France ’40 is a
hex-and-counter game for two players. It focuses on the German invasion of
France in May and June 1940. The game comes with two scenarios, each with its
own separate map, and a campaign game that combines both scenarios into one
game. First is the Sickle Cut scenario, which depicts the German advance
towards the English Channel in May 1940. Germans start at the eastern edge of
the map, near the town of Namur and in the Ardennes forest south of it, and must
advance towards the English Channel and the coastal town of Abbeville in the
west. The Allied player, commanding combined France and British forces, plays a
defensive game and must attempt to stop, or at least slow down, the German
offensive.</p>
<div class="thumbnail">
<figure>
<a href="/images/posts/2025-04-24-france-40-2nd-edition-a-boardgame-review/sickle_cut_at_start.jpg"><img src="/images/posts/2025-04-24-france-40-2nd-edition-a-boardgame-review/sickle_cut_at_start_thumbnail.jpg" /></a>
<figcaption>
Beginning of Sickle Cut scenario.
</figcaption>
</figure>
</div>
<div class="thumbnail">
<figure>
<a href="/images/posts/2025-04-24-france-40-2nd-edition-a-boardgame-review/sickle_cut_in_progress.jpg"><img src="/images/posts/2025-04-24-france-40-2nd-edition-a-boardgame-review/sickle_cut_in_progress_thumbnail.jpg" /></a>
<figcaption>
Germans attempting to cross the Meuse river.
</figcaption>
</figure>
</div>
<p>The second scenario, called Dynamo, takes place in late May and early June and
depicts the Allied evacuation from Dunkirk. The Allies are tasked with
evacuating their troops, which requires conducting an organized retreat that
slows down the German advance towards the coast. This scenario also involves
Belgian troops fighting on the Allied side, though they surrender on 28 May.</p>
<div class="thumbnail">
<figure>
<a href="/images/posts/2025-04-24-france-40-2nd-edition-a-boardgame-review/dynamo_at_start.jpg"><img src="/images/posts/2025-04-24-france-40-2nd-edition-a-boardgame-review/dynamo_at_start_thumbnail.jpg" /></a>
<figcaption>
Beginning of Dynamo scenario.
</figcaption>
</figure>
</div>
<div class="thumbnail">
<figure>
<a href="/images/posts/2025-04-24-france-40-2nd-edition-a-boardgame-review/dynamo_in_progress.jpg"><img src="/images/posts/2025-04-24-france-40-2nd-edition-a-boardgame-review/dynamo_in_progress_thumbnail.jpg" /></a>
<figcaption>
Allied defense collapsing halfway through the game.
</figcaption>
</figure>
</div>
<p>Every scenario can play out in many different ways. Sometimes, a game will
result in historical outcomes. Other times, it will be a complete opposite of
what happened. I have played a Sickle Cut game, where the German player’s plan
to advance through the Ardennes completely failed. As a result, the entire
German offensive was stopped, with barely any progress made towards the English
Channel.</p>
<div class="thumbnail">
<figure>
<a href="/images/posts/2025-04-24-france-40-2nd-edition-a-boardgame-review/sickle_cut_end.jpg"><img src="/images/posts/2025-04-24-france-40-2nd-edition-a-boardgame-review/sickle_cut_end_thumbnail.jpg" /></a>
<figcaption>
End of Sickle Cut, with Germans making practically no progress towards the Channel.
</figcaption>
</figure>
</div>
<div class="thumbnail">
<figure>
<a href="/images/posts/2025-04-24-france-40-2nd-edition-a-boardgame-review/dynamo_end.jpg"><img src="/images/posts/2025-04-24-france-40-2nd-edition-a-boardgame-review/dynamo_end_thumbnail.jpg" /></a>
<figcaption>
End of Dynamo scenario. Allies have been almost completely wiped out.
</figcaption>
</figure>
</div>
<p>Rule complexity of France ’40 is comparable with other WWII games by Mark
Simonitch. Even though each scenario comes with its unique rules —
e.g. train movement in Sickle Cut or beach evacuation in Dynamo — the
overall amount of special rules isn’t large, and they don’t add much complexity.
But most importantly, the overwhelming majority of terrain on both maps is
either a clear terrain or a forest, making it very easy to memorize terrain
properties and allowing to avoid frequent checking of Terrain Effect Chart. As
a result, the game plays quickly — by wargaming standards at least. Once
both players know the rules, the Dynamo scenario can be played in about 3 hours,
while Sickle Cut takes about 4 hours.</p>
<p>For these precise reasons, out of all games by Mark Simonitch, this is the one
that makes it to my table most often. The short playing time makes it easy to
play the game multiple times and experiment with different strategies. I in
particular enjoy playing Dynamo scenario as the Allied, where blocking the
German advance feels like a puzzle to solve. A puzzle that is different every
time, because the opponent never makes the same decisions.</p>
<h2 id="gmt-games-needs-help-because-of-the-tariffs">GMT Games needs help because of the tariffs</h2>
<p>Unfortunately, the timing of this post is not accidental. If you follow the
news, then you are aware of recent tariffs introduced by Donald Trump on goods
imported from China. With the situation changing daily it is hard to tell how
this is going to end, but in their current form these tariffs are an existential
threat to many American game publishers, including GMT Games. There is <a href="https://boardgamegeek.com/blog/1/blogpost/172959/tariff-talk-from-stonemaier-cephalofair-game-trayz">a good
post on
BoardGameGeek</a>
that compiles explanations from various publishers on why it is not possible to
move production from China to the USA. <a href="https://mailchi.mp/2438d2843c59/april-17-update-from-gmt-tariffs-and-action-plan-new-p500s-updated-production-outlook-designer-updates-and-more">The latest customer update from GMT
Games</a>
goes into more details on the current financial situation — a highly
recommended read. The gist is that we can help GMT Games and other publishers
to weather this storm by purchasing games directly from them, allowing to
maintain financial fluidity in the coming weeks.</p>

        <p><a href="../blog.html">Back</a></p>
    </section>
</article>
]]></description>
    <pubDate>26/04/2025</pubDate>
    <guid>https://jstolarek.github.io/posts/2025-04-24-france-40-2nd-edition-a-boardgame-review.html</guid>
    <dc:creator>Jan Stolarek</dc:creator>
</item>
<item>
    <title>The Legend of Heroes&#58; Trails in the Sky FC. Game review</title>
    <link>https://jstolarek.github.io/posts/2025-04-19-the-legend-of-heroes-trails-in-the-sky-fc-game-review.html</link>
    <description><![CDATA[<article>
    <section class="header">
        Posted on 19/04/2025
    </section>
    <section>
        <h1 id="the-legend-of-heroes-trails-in-the-sky-fc.-game-review">The Legend of Heroes: Trails in the Sky FC. Game review</h1>
<p>Like most of the Western players, my first experience of a JRPG — Japanese
Role-Playing Game — was Final Fantasy VII back in 1997. Since then, I
have played many JRPG titles, but there are still several long-running series
that I have yet to experience. One of them is Falcom’s <em>The Legend of Heroes</em>,
and in particular its <em>Trails</em> subseries. After hearing many recommendations, I
finally decided to give the series a try.</p>
<p>The first entry in <em>The Legend of Heroes</em> series appeared in 1989 and to this
day the series has grown to around 20 titles. I’m not going to walk through
<a href="https://en.wikipedia.org/wiki/The_Legend_of_Heroes#History">all of the series’
history</a>, and will
only note that <em>Trails</em> subseries started with <em>Trails in the Sky FC</em><a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> back
in 2004. Games in the series are grouped into duologies, trilogies, and
tetralogies, such that a single story spans over several games. Given that all
the <em>Trails</em> games are set in the same world and build on top of each other, the
series always seemed very difficult to get into. I finally decided to bite the
bullet and start with the very first one, the already mentioned <em>Trails in the
Sky FC</em>, a first entry in the <em>Trails in the Sky</em> trilogy.</p>
<p>The game was originally released back in 2004 for PC and has seen several
re-releases, ports, and revisions since then. I was considering whether to play
the PSP version or the <a href="https://www.gog.com/pl/game/the_legend_of_heroes_trails_in_the_sky">PC version from
GOG</a>, but
then learned of <em>Trails in the Sky FC Evolution</em>, a PS Vita remake with new
artwork and voice acting. This seemed like the best option to me — from
experience, I know that playing on a handheld greatly increases the chances of
me finishing a game. The only catch is that Evolution was not officially
translated into English. Luckily, there are fan-made patches that apply PC
translation to the Vita version<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>. Given how this keeps the original Japanese
voice acting, it seems to me like the ultimate version — at least until I
learn Japanese, so that I can experience the game without any translation.</p>
<div class="thumbnail">
<figure>
<a href="/images/posts/2025-04-19-the-legend-of-heroes-trails-in-the-sky-fc-game-review/title.jpg"><img src="/images/posts/2025-04-19-the-legend-of-heroes-trails-in-the-sky-fc-game-review/title_thumbnail.jpg" /></a>
</figure>
</div>
<p><em>Trails in the Sky</em> — I refuse to abbreviate the title — takes place
in Liberl kingdom. Two main protagonists are Estelle and Joshua Bright, teenage
step-siblings, who aspire to become Bracers. Bracers are something between a
police force and private detectives — they fight crime, they fight
monsters, and generally help to keep citizens of Liberl safe. In their quest to
become Bracers, Estelle and Joshua are sent on a journey across the land to get
to know the kingdom and gain experience by working at the local Bracer Guild
branches.</p>
<div class="thumbnail">
<figure>
<a href="/images/posts/2025-04-19-the-legend-of-heroes-trails-in-the-sky-fc-game-review/estelle.jpg"><img src="/images/posts/2025-04-19-the-legend-of-heroes-trails-in-the-sky-fc-game-review/estelle_thumbnail.jpg" /></a>
</figure>
<figcaption>
Estelle is an impulsive bubblehead at first, but grows greatly as the game progresses.
</figcaption>
</div>
<div class="thumbnail">
<figure>
<a href="/images/posts/2025-04-19-the-legend-of-heroes-trails-in-the-sky-fc-game-review/joshua.jpg"><img src="/images/posts/2025-04-19-the-legend-of-heroes-trails-in-the-sky-fc-game-review/joshua_thumbnail.jpg" /></a>
</figure>
<figcaption>
Joshua is cool, composed, and very mature for his age.
</figcaption>
</div>
<div class="thumbnail">
<figure>
<a href="/images/posts/2025-04-19-the-legend-of-heroes-trails-in-the-sky-fc-game-review/joshua_crossdressing.jpg"><img src="/images/posts/2025-04-19-the-legend-of-heroes-trails-in-the-sky-fc-game-review/joshua_crossdressing_thumbnail.jpg" /></a>
</figure>
<figcaption>
Joshua getting dressed as a girl is a running joke in the game.
</figcaption>
</div>
<p>This setup is unlike most JRPGs. Although it is not uncommon to play as a
teenager, the stakes in the plot tend to be high. You either save a friend or
family member, fight to save the kingdom, or even the whole world. In <em>Trails
in the Sky</em>, not so much. Most of the time, you just help local authorities and
citizens. At the beginning of the game, there is an incident with pirates
hijacking one of the airships travelling between Liberl’s cities, and it does
seem like a beginning of a larger plot, but this quickly fizzles out and does
not really get anywhere until towards the end of the game. Instead, the player
is fed smaller breadcrumbs throughout the game, hinting there is a major plot
going on. And indeed there is, but all the threads only converge towards the
end, when all the various incidents encountered along the way are combined into
a coherent, overarching scheme by a master villain and the stakes indeed become
high. And then the game ends with a massive cliffhanger, which is only
followed-up on in <em>Trails in the Sky SC</em>.</p>
<p>Like in other RPGs, there are side quests alongside the main story. Many are
posted on bulletin boards in each town’s Bracer Guild branch, while others are
hidden and available only at a specific place and time. These optional quests
can be permanently missed if overlooked.</p>
<div class="thumbnail">
<figure>
<a href="/images/posts/2025-04-19-the-legend-of-heroes-trails-in-the-sky-fc-game-review/dean.jpg"><img src="/images/posts/2025-04-19-the-legend-of-heroes-trails-in-the-sky-fc-game-review/dean_thumbnail.jpg" /></a>
</figure>
<figcaption>
All those seemingly unrelated local incidents converge towards the end of the game.
</figcaption>
</div>
<p>Most of the game mechanics in <em>Trails in the Sky</em> are fairly straightforward.
For me, the biggest novelty was the battle system. Like in many older JRPGs, it
is turn-based, but it includes moving on a grid. This means that positioning
becomes crucial: melee weapons have a limited range, and effectiveness of area
attacks depends on relative position to the enemy. Beyond that, the battle
system is fairly standard, with unique character abilities (called Crafts),
magic (called Arts), items etc. Magical spells are obtained by inserting
magical stones (quartz) into weapons, which resembles materia from Final Fantasy
VII, but in practice works differently.</p>
<p>There are no random battles in <em>Trails in the Sky</em>. Rather, the enemies roam
the map freely. They can be outmanoeuvred and attacked from behind for an
in-battle advantage and experience bonus, or entirely avoided if one does not
wish to fight. The overall difficulty of the game is not high, except maybe for
some optional monsters and two or three boss fights.</p>
<div class="thumbnail">
<figure>
<a href="/images/posts/2025-04-19-the-legend-of-heroes-trails-in-the-sky-fc-game-review/combat.jpg"><img src="/images/posts/2025-04-19-the-legend-of-heroes-trails-in-the-sky-fc-game-review/combat_thumbnail.jpg" /></a>
</figure>
<figcaption>
Fight with the final boss.
</figcaption>
</div>
<div class="thumbnail">
<figure>
<a href="/images/posts/2025-04-19-the-legend-of-heroes-trails-in-the-sky-fc-game-review/quartz.jpg"><img src="/images/posts/2025-04-19-the-legend-of-heroes-trails-in-the-sky-fc-game-review/quartz_thumbnail.jpg" /></a>
</figure>
<figcaption>
Quartz might seem similar to materia, but the way it provides spells is actually quite different.
</figcaption>
</div>
<div class="thumbnail">
<figure>
<a href="/images/posts/2025-04-19-the-legend-of-heroes-trails-in-the-sky-fc-game-review/monster.jpg"><img src="/images/posts/2025-04-19-the-legend-of-heroes-trails-in-the-sky-fc-game-review/monster_thumbnail.jpg" /></a>
</figure>
<figcaption>
An optional boss fight. I appreciate how the game does not allow fighting it accidentally.
</figcaption>
</div>
<p>Unlike most older JRPGs, <em>Trails in the Sky</em> does not have an overworld map.
You can only travel linearly through the world by using roads connecting cities
and villages. This is something that I really dislike, because the world just
feels like a big corridor. There is no fast travel; backtracking to earlier
locations is insufferable, and I just never bothered to do it, beyond what the
plot required from me. Luckily, it requires barely any.</p>
<p>One thing that I was completely unprepared for in <em>Trails in the Sky</em> were the
lengthy dialogues and cutscenes. I have mostly played 16-bit (SNES) and early
32-bit (PSX) JRPGs, where technical limitations forced the dialogues to be short
but succinct. These technical limitations are no more, and writers of <em>Trails
in the Sky</em> made full use of it. As a result, a series of dialogues can easily
last 15 minutes or even more, which is not far away from watching an anime
episode. Because of these lengthy dialogues and a slowly developing plot, I
have stalled during my first playthrough back in 2023, after playing for about
17 hours. Combined with a slowly-developing plot, it felt like I am spending a
lot of time with the game, but not really getting anywhere, so I just stopped
playing. In the first half of 2024 I picked up where I left off a year before,
this time being fully prepared for the slow pace of the game, and played it to
completion. Once I set my expectations right, the game was indeed a joy to
play. In particular, I really began to enjoy the dialogues. They flesh out the
characters in more detail than any other JRPG I have played up to this point
— except maybe for <em>Persona</em> games — which is important to make the
numerous characters feel unique and authentic. What is interesting from a
gameplay perspective, Estelle and Joshua are the only two permanent playable
characters. Many other playable characters join you at various points in the
plot, but they depart when the events dictate so. This is something that adds a
lot of authenticity to the story.</p>
<div class="thumbnail">
<figure>
<a href="/images/posts/2025-04-19-the-legend-of-heroes-trails-in-the-sky-fc-game-review/jill.jpg"><img src="/images/posts/2025-04-19-the-legend-of-heroes-trails-in-the-sky-fc-game-review/jill_thumbnail.jpg" /></a>
</figure>
<figure>
<a href="/images/posts/2025-04-19-the-legend-of-heroes-trails-in-the-sky-fc-game-review/dorothy.jpg"><img src="/images/posts/2025-04-19-the-legend-of-heroes-trails-in-the-sky-fc-game-review/dorothy_thumbnail.jpg" /></a>
</figure>
<figure>
<a href="/images/posts/2025-04-19-the-legend-of-heroes-trails-in-the-sky-fc-game-review/kloe.jpg"><img src="/images/posts/2025-04-19-the-legend-of-heroes-trails-in-the-sky-fc-game-review/kloe_thumbnail.jpg" /></a>
</figure>
<figcaption>
You encounter a lot of characters along the way.
</figcaption>
</div>
<p>In the end, it took me a total of 55 hours to finish the First Chapter, although
this time was spread out over approximately 1.5 years. <em>Trails in the Sky</em> is
light on mechanics and difficulty, but offers a world and characters fleshed out
in great detail. The pace of the story is quite slow, which initially was an
obstacle for me. But once I set my expectations right, I really enjoyed my time
with the game. I hope to play the <em>Second Chapter</em> eventually, although other
JRPG titles have been occupying my time recently.</p>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr />
<ol>
<li id="fn1"><p>The “FC” suffix stands for <em>First Chapter</em> and is sometimes omitted. The
second game is known as <em>Trails in the Sky SC</em> — SC standing for the
<em>Second Chapter</em> — or <em>Trails in the Sky 2nd</em>.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>A friend, who played on PC, told me there are also reverse patches that
apply changes from the Evolution version on Vita to the PC release.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

        <p><a href="../blog.html">Back</a></p>
    </section>
</article>
]]></description>
    <pubDate>19/04/2025</pubDate>
    <guid>https://jstolarek.github.io/posts/2025-04-19-the-legend-of-heroes-trails-in-the-sky-fc-game-review.html</guid>
    <dc:creator>Jan Stolarek</dc:creator>
</item>
<item>
    <title>Goodbye, Google&#58; Switching from GMail to Mailbox</title>
    <link>https://jstolarek.github.io/posts/2024-12-03-goodbye-google-switching-from-gmail-to-mailbox.html</link>
    <description><![CDATA[<article>
    <section class="header">
        Posted on 03/12/2024
    </section>
    <section>
        <h1 id="goodbye-google-switching-from-gmail-to-mailbox">Goodbye, Google: Switching from GMail to Mailbox</h1>
<p>In recent years, I have been making attempts to minimize using services provided
by Google, the primary concern being privacy. In my <a href="2024-09-27-goodbye-google-switching-from-google-search-to-kagi.html">earlier
post</a>, I
wrote about using <a href="https://www.kagi.com">Kagi</a> as my search engine of choice.
Today, I want to talk about <a href="https://mailbox.org/">Mailbox.org</a>, a paid email
provider that I migrated to from GMail.</p>
<h2 id="my-expectations-and-why-previous-email-providers-didnt-meet-them">My expectations and why previous email providers didn’t meet them</h2>
<p>I heavily rely on email in my daily life. I always had at least two accounts: a
private one and a professional one at my current workplace. Most of the time, I
had more than one mailbox for work. In order to manage multiple email accounts
conveniently, I use a desktop email client. Thus, a basic requirement for me is
that an email provider allows reading and sending emails via a client. This
sounds like a really, really trivial requirement, but you will see in a moment
that for some email providers this is far from obvious.</p>
<p>For the most part of the last 25 years, I have used a free email account from
<a href="https://www.onet.pl">Onet</a>, a Polish news portal and email provider - think
Yahoo. It being free came at a price of receiving advertising emails directly
to the inbox. Luckily, it is trivial to filter out such mails with a custom
filter in the email client and never see those adds. As such, I was happy with
services provided by Onet. However, at some point they started to silently put
restrictions on emails send via desktop clients. In particular, sending emails
that only contained links or attachments, or were simply too short, resulted in
them being silently dropped by the SMTP server. Imagine a situation where you
are making arrangements with someone and reply simply with “Yes”, and that email
gets silently dropped and never makes it to the other person. Or you just want
to send someone a link, but that person never receives it. I have been in
multiple such situations without realizing it. Dropping emails for no good
reason would be bad enough in itself. But doing so silently in such a way that
the sender does not even know that the message was not delivered is simply too
much. When I realized what is going on, and verified with the provider that
this is an intended behaviour that’s part of their “security policy” (sic!), I
knew I have to start looking for a new email service.</p>
<p>Unfortunately, at this point in time, I was heavily occupied with events in my
private life and did not have the time to properly research paid alternatives.
And so I went with an easily available solution: GMail. Well, that was a
mistake. Firstly, GMail complicates usage of clients that don’t support OAuth
(mine doesn’t). Secondly, GMail places sent emails in the inbox. If you send
an email via a client, your client will then download that email into your
inbox, showing it as a new email. This is a major annoyance. Again, it can be
sorted out with some extra work and custom filters, but this is not how email
should work.</p>
<p>I lived with GMail annoyances for a couple of years, until last November I
finally decided to bite the bullet and move to a new email provider.</p>
<h2 id="mailbox.org-pros-and-cons">Mailbox.org: Pros and Cons</h2>
<p>After some research, and recommendations from friends, I decided on
<a href="https://mailbox.org/">Mailbox.org</a>, which offers a good set of features at a
competitive price. As mentioned earlier, one of my motivations to move away
from Google are privacy concerns. Mailbox.org operates from Germany, which
means it must follow the EU’s strict data protection laws. To me, this was an
important argument in favour of using Mailbox.org.</p>
<p>Mailbox.org offers lots of neat little features that one does not typically get
from free email providers such as GMail. These include multiple email aliases,
disposable addresses, encryption support, detailed SPAM protection settings, and
mailbox backups, among others. Aside from email, Mailbox.org also provides a
suite of online applications. These include:</p>
<ul>
<li>An address book and calendar.</li>
<li>A TODO list that allows to manage tasks, track their progress, set
deadlines, attach files, etc. I couldn’t figure out a way to integrate it
with a calendar, but I admit I haven’t tried very hard. Perhaps there’s a
way of doing it.</li>
<li>Cloud storage with 5GB of space (in the Standard plan).</li>
<li>XMPP chat</li>
<li>Video conferencing based on <a href="https://opentalk.eu">OpenTalk</a>.</li>
<li>Etherpad, a lightweight alternative to Google Docs.</li>
<li>Creating polls and event scheduling based on
<a href="https://framadate.org">Framadate</a>.</li>
</ul>
<p>It is good to see alternatives to GSuite finally being offered, though I admit I
have not tested most of these tools, since I rarely collaborate with others via
such tools and tend to work on the desktop. I only really tried using Etherpad
and, frankly speaking, the experience wasn’t great. Firstly, Etherpad seems to
forget which edits were made by whom, i.e. rather than associating edits with a
Mailbox.org account it seems to be using cookies that have short expiration
dates. Secondly, it frequently resets to default display settings, which is
quite annoying - presumably cookies, again. But worst of all, it isn’t
reliable. I had a situation where a document I shared with someone became
completely broken and unresponsive. After contacting the support, I was told
that they had an infrastructure problem and the only way to solve the problem is
to create a new document and copy the contents of the broken document there. It
was a one-time incident, but something like this should not ever happen if the
tool is to be considered reliable.</p>
<p>Beyond that, Mailbox.org offers <a href="https://kb.mailbox.org/en/private/">good technical
documentation</a> - and I really mean that.
This documentation does not shy away from providing full technical details so
that a knowledgeable user gets all the information they need.</p>
<p>And lastly, the service works with an email client without any problems. This
should be obvious, but as demonstrated by my experiences, it isn’t always the
case.</p>
<p>There are a couple of cons, though, aside from the already mentioned Etherpad
incident. Possibly the biggest usability issue are strict SPAM filters. By
“strict” I mean following all sorts of standards, that many big providers on the
internet (such as Microsoft) don’t follow. As a result, some incoming emails
don’t get delivered or arrive delayed. In particular, I have found
<a href="https://en.wikipedia.org/wiki/Greylisting_(email)">greylisting</a> to cause
trouble. Thankfully, SPAM filter behaviour can be modified in the settings, but
I don’t like how the default settings are problematic, even if, strictly
speaking, the fault does not lie with Mailbox.org.</p>
<p>Mailbox.org offers online technical support - which in itself is good and yet
another thing one does not get with free email services - but I have found that
support to be highly incompetent. I contacted support on three different
occasions, and each experience was bad. I encountered consultants that were
arrogant or lacked knowledge, trying to convince me that the behaviour I am
experiencing is a problem caused by my browser and sending me through many
pointless debugging steps, only to admit in the end that this is actually an
intended behaviour of the service.</p>
<p>Speaking of “intended behaviours of the service”, one of them is repeatedly
logging out of the web client. Not that I use the web client frequently, but
having to log in every other day was annoying when I first started using the
service and frequently experimented with various settings. I initially thought
that this was a bug, since the settings allow to disable automatic logout, but I
was eventually told that this is all intentional - despite what the settings
seem to imply.</p>
<p>There are a few more minor annoyances in the web client, such as the inability
to click any links in emails moved to the SPAM folder. So if you want to click
an unsubscribe link you first need to move an email to the inbox folder, click
the link, and move it back to spam. But again, this isn’t really a huge problem
for me.</p>
<p>One last issue is a really minor one, but when I initially got the new email
address I kept mistaking the <code>.org</code> domain with <code>.com</code> and on several occasions
nearly provided an incorrect email address.</p>
<h2 id="summary">Summary</h2>
<p>After many years of struggling with free email providers, I finally have a
mailbox that works like it should. I regret not making this move earlier, and I
regret even more ever getting involved with GMail. This was a mistake that I
should not have done, given how hard it is to entirely phase out an old email
address.</p>

        <p><a href="../blog.html">Back</a></p>
    </section>
</article>
]]></description>
    <pubDate>03/12/2024</pubDate>
    <guid>https://jstolarek.github.io/posts/2024-12-03-goodbye-google-switching-from-gmail-to-mailbox.html</guid>
    <dc:creator>Jan Stolarek</dc:creator>
</item>
<item>
    <title>Japanese Video Game Obscurities.  Book review</title>
    <link>https://jstolarek.github.io/posts/2024-12-02-japanese-video-game-obscurities-book-review.html</link>
    <description><![CDATA[<article>
    <section class="header">
        Posted on 02/12/2024
    </section>
    <section>
        <h1 id="japanese-video-game-obscurities.-book-review">Japanese Video Game Obscurities. Book review</h1>
<p>In the past couple of months I have been indulging in buying all sorts of retro
stuff from Japan, mostly artbooks, laserdiscs and games. Though I don’t
understand Japanese, at least to an extent that would allow me to fully enjoy
purchased goods, I thought it would be nice to have Japanese releases of some of
my favourite games. The primary motivation is that European and US editions
tend to be prohibitively expensive these days, whereas releases from Japan tend
to be rather cheap - quite understandably, given the language barrier.</p>
<p>While browsing shopping sites for retro games - I happen to have an NTSC-J
version of Sega Saturn - I often run into obscure games that were never released
outside of Japan. Typically, I then search online for information on what these
unknown games even are. A page that comes up very frequently in search results
is <a href="http://www.hardcoregaming101.net/">Hardcore Gaming 101</a>, which seems to
specialize in all sorts of niche games from all eras. I was then very pleased
to learn that Hardcore Gaming 101 also publishes books, one of them being
<a href="http://www.hardcoregaming101.net/books/hg101-presents-japanese-video-game-obscurities/">“Japanese Video Game
Obscurities”</a>
by Kurt Kalata, published in 2019. Once I learned of its existence, I knew I
need to have it.</p>
<div class="thumbnail">
<figure>
<a href="/images/posts/2024-12-02-japanese-video-game-obscurities-book-review/cover.jpg"><img src="/images/posts/2024-12-02-japanese-video-game-obscurities-book-review/cover_thumbnail.jpg" /></a>
</figure>
</div>
<p>The book contains reviews of 101 games, the majority of which were not
officially released outside of Japan. The focus is on retro titles for both
consoles and PCs, with most of the reviewed games being released in the 90s, but
also some titles from 80s and 2000s. Reviews are grouped into chapters by
genre, with each review taking two pages: one page for the review itself and one
for the screenshots.</p>
<div class="thumbnail">
<figure>
<a href="/images/posts/2024-12-02-japanese-video-game-obscurities-book-review/princess_crown.jpg"><img src="/images/posts/2024-12-02-japanese-video-game-obscurities-book-review/princess_crown_thumbnail.jpg" /></a>
</figure>
</div>
<div class="thumbnail">
<figure>
<a href="/images/posts/2024-12-02-japanese-video-game-obscurities-book-review/ore_no_shikabane.jpg"><img src="/images/posts/2024-12-02-japanese-video-game-obscurities-book-review/ore_no_shikabane_thumbnail.jpg" /></a>
</figure>
</div>
<div class="thumbnail">
<figure>
<a href="/images/posts/2024-12-02-japanese-video-game-obscurities-book-review/chaos_seed.jpg"><img src="/images/posts/2024-12-02-japanese-video-game-obscurities-book-review/chaos_seed_thumbnail.jpg" /></a>
</figure>
</div>
<div class="thumbnail">
<figure>
<a href="/images/posts/2024-12-02-japanese-video-game-obscurities-book-review/jesus.jpg"><img src="/images/posts/2024-12-02-japanese-video-game-obscurities-book-review/jesus_thumbnail.jpg" /></a>
</figure>
</div>
<div class="thumbnail">
<figure>
<a href="/images/posts/2024-12-02-japanese-video-game-obscurities-book-review/mizzurna_falls.jpg"><img src="/images/posts/2024-12-02-japanese-video-game-obscurities-book-review/mizzurna_falls_thumbnail.jpg" /></a>
</figure>
</div>
<div class="thumbnail">
<figure>
<a href="/images/posts/2024-12-02-japanese-video-game-obscurities-book-review/love_and_destroy.jpg"><img src="/images/posts/2024-12-02-japanese-video-game-obscurities-book-review/love_and_destroy_thumbnail.jpg" /></a>
</figure>
</div>
<div class="thumbnail">
<figure>
<a href="/images/posts/2024-12-02-japanese-video-game-obscurities-book-review/suzuki_bakuhatsu.jpg"><img src="/images/posts/2024-12-02-japanese-video-game-obscurities-book-review/suzuki_bakuhatsu_thumbnail.jpg" /></a>
</figure>
</div>
<p>As you can see in the photos above, the reviews are short, yet they are
unbelievably succinct. In just a few paragraphs of text, they convey
surprisingly large amounts of information and insight, both about the game
itself and the context surrounding it. Each review offers multiple trails of
further research, typically on the studio’s previous and future titles, similar
games, and artists involved.</p>
<p>If you are interested in retro gaming and enjoy learning about games that didn’t
make it to the West, then “Japanese Video Game Obscurities” is a must-read. It
is well researched, writing is top quality, and choice of screenshots is very
good. The only real complaint I have about the book is the lack of an
alphabetic index of titles, forcing the reader to search the (non-alphabetic)
table of contents when looking for a particular game. Also, the illustration on
the cover looks quite amateurish. That’s not a serious complaint, though
— just don’t let the cover mislead you.</p>

        <p><a href="../blog.html">Back</a></p>
    </section>
</article>
]]></description>
    <pubDate>02/12/2024</pubDate>
    <guid>https://jstolarek.github.io/posts/2024-12-02-japanese-video-game-obscurities-book-review.html</guid>
    <dc:creator>Jan Stolarek</dc:creator>
</item>
<item>
    <title>Goodbye, Google&#58; Switching from Google Search to Kagi</title>
    <link>https://jstolarek.github.io/posts/2024-09-27-goodbye-google-switching-from-google-search-to-kagi.html</link>
    <description><![CDATA[<article>
    <section class="header">
        Posted on 27/09/2024
    </section>
    <section>
        <h1 id="goodbye-google-switching-from-google-search-to-kagi">Goodbye, Google: Switching from Google Search to Kagi</h1>
<p>Last year, I wrote about <a href="2023-10-09-lineageos-on-samsung-s7-an-experience-report.html">my experience of installing LineageOS on my
smartphone</a>. The
goal was to have an Android phone that is free of Google spyware. Since then, I
have been gradually moving away from using services provided by Google,
primarily the search engine and email services. In this post, I want to write
about <a href="https://kagi.com/">Kagi</a>, a search engine that I’ve been using since last
October.</p>
<p>Whatever product is being offered on the market, it is crucial that its
customers are satisfied and willing to pay for it. The problem with Google
Search is that its users, i.e. people using Google to find information on the
Internet, are not its customers. It is the advertisers that pay Google for
their service of positioning the ads. And so, search results provided by Google
must first and foremost benefit the advertisers, with the user experience being
a secondary matter. This is nothing new. The problem has been anticipated by
Google creators Sergey Brin and Lawrence Page in their 1998 paper<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>:</p>
<blockquote>
<p>The goals of the advertising business model do not always correspond to
providing quality search to users. (…) we expect that advertising funded
search engines will be inherently biased towards the advertisers and away from
the needs of the consumers.</p>
</blockquote>
<p>In the past years, this has been the subject of a wide discussion sparked by the
gradual degradation of Google’s search results quality.</p>
<p>For a couple of years now, I have not been using Google as my primary search
engine. I switched to DuckDuckGo instead. For the most time, DuckDuckGo worked
well for me, but every now and then it couldn’t find what I was looking for, and
I had to use Google as a fallback.</p>
<h2 id="better-search-results">Better search results</h2>
<p>About a year ago, I heard about Kagi, a new search engine that people have been
raving about. Long story short, I decided to give it a try. Since then, Kagi
has improved my web searching experience by offering better results than its
competitors. No more falling back to Google or DuckDuckGo.</p>
<div class="thumbnail">
<figure>
<a href="/images/posts/2024-09-27-goodbye-google-switching-from-google-search-to-kagi/kagi_main.png"><img src="/images/posts/2024-09-27-goodbye-google-switching-from-google-search-to-kagi/kagi_main.png" /></a>
</figure>
</div>
<p>The first couple of weeks of using Kagi felt… strange. The search results were
sometimes so accurate that they felt scary. Here’s an example. In a <a href="2024-08-21-fremen-zone-creating-a-website-using-only-html-and-css.html">recent
post about my fan website Fremen
Zone</a>, I
mentioned setting up GitHub actions to validate HTML. I used
<a href="https://github.com/Cyb3r-Jak3/html5validator-action">html5validator-action</a> for
this. I initially ran into a setup problem, where every run of the action
resulted in “There is no git repository detected” error. And so I used Kagi to
search for “Github actions Error: There is no git respository detected” (yes,
there’s a typo in the search phrase). Here is the search result I got from
Kagi:</p>
<div class="thumbnail">
<figure>
<a href="/images/posts/2024-09-27-goodbye-google-switching-from-google-search-to-kagi/kagi_win.png"><img src="/images/posts/2024-09-27-goodbye-google-switching-from-google-search-to-kagi/kagi_win.png" /></a>
</figure>
</div>
<p>The first result is literally a bug report for the project I was using with the
exact same problem I was facing. It doesn’t get any more accurate than that.
By contrast, here are results for the same search phrase from Google:</p>
<div class="thumbnail">
<figure>
<a href="/images/posts/2024-09-27-goodbye-google-switching-from-google-search-to-kagi/google_fail.png"><img src="/images/posts/2024-09-27-goodbye-google-switching-from-google-search-to-kagi/google_fail.png" /></a>
</figure>
</div>
<p>And from DuckDuckGo:</p>
<div class="thumbnail">
<figure>
<a href="/images/posts/2024-09-27-goodbye-google-switching-from-google-search-to-kagi/ddg_fail.png"><img src="/images/posts/2024-09-27-goodbye-google-switching-from-google-search-to-kagi/ddg_fail.png" /></a>
</figure>
</div>
<p>Neither of these results was helpful in any way<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>. This is just one example,
but this happened over and over again.</p>
<h2 id="is-paying-for-a-search-engine-worth-it">Is paying for a search engine worth it?</h2>
<p>Let’s get this one out of the way: Kagi is a paid service. It gives up entirely
on the ad-based business model, requiring the users to pay with real money and
not their private data. The question is, whether it is worth to pay for a
service that everyone else offers for free?</p>
<p>After using Kagi - and paying for it - for a year, to me the answer is a “yes”.
Making Kagi a paid search engine finally aligns the needs of the users with the
needs of the customers, because now these are the same people. I no longer see
search results because the advertisers want me to see them. The end result is a
service that is worth paying for. There are some caveats, which I will get to
in a moment.</p>
<p>Kagi offers several subscription plans. I am not going to comment on the
affordability, since that is going to be different for everyone depending on
income. I will warn about the free trial though. Kagi allows you to try a
hundred searches for free. This is how I started at first, but quickly noticed
that, since the number of searches was limited, I would tend to use DuckDuckGo
by default, and only use Kagi if DDG failed. That doesn’t really give the true
taste of Kagi’s usability. It wasn’t until I decided to try the paid plan for a
single month that I really saw the benefits of Kagi. I also have some
scepticism about Kagi’s Starter plan that, at the moment of this writing, offers
300 searches a month. Kagi quotes statistics from Google and DuckDuckGo, which
claim an average of 100 and 30 (sic!) monthly searches per user, respectively.
I find these numbers unbelievably low. Kagi offers search statistics, and I can
see there was not a single month when I would use less than 300 searches. I
typically perform 340 searches a month, though there have been months when that
number went up to nearly 600. And that is only when using Kagi on the desktop.
My wife, who uses Kagi on desktop and mobile, has an average of 200 searches
more per month<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>.</p>
<h2 id="features">Features</h2>
<p>Searching is obviously the most important thing in a search engine, but Kagi has
a few more features. Let’s have a brief look at some of them.</p>
<p>Firstly, Kagi offers lenses, which can be though of as a predefined set of
filters. For example, there’s an academic lens that will search for results on
web pages related to science and academia. There are a bunch of others, for
example usenet archives, fediverse forums, programming or recipes.</p>
<p>One kind of lens that deserves a special mention is the <a href="https://blog.kagi.com/small-web">Small
Web</a>. This is Kagi’s initiative to promote
personal websites and blogs, as they can be a great source of original opinions
and knowledge.</p>
<p>Kagi also works on adding LLM capabilities to the search experience. This is
one feature I am very sceptical about - I don’t share the hype around AI - and
the Kagi team definitely is well aware of the concerns surrounding AI and
ensures that user privacy is maintained, and no data generated by Kagi users is
used for training. As part of the standard payment plans, Kagi offers the Fast
Answer, which can be triggered by appending a question mark at the end of the
query. This will send the question to a LLM and provide an AI-generated answer,
together with references to sources from which the information was taken. This
feature works just like all the other large language models of today:
unreliably. Sometimes it gives good answers, and sometimes it fails, often in
subtle and non-obvious ways. For this reason, I approach this feature with
caution. Kagi also offers an AI
<a href="https://blog.kagi.com/announcing-assistant">Assistant</a> as part of the most
expensive Ultimate plan, but I have not tested it<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>.</p>
<p>There is also the Summarizer, embedded into the Kagi browser plugin (more on the
plugin in the next section), which can summarize the currently viewed web page.
I have only ever used the Summarizer to see if it works, and it seems to do the
job.</p>
<p>Kagi offers a lot of customization options. It is possible to customize the
layout of the search result page, either by choosing from predefined settings or
by providing a custom CSS for the results page. This, I have to say, is pretty
cool. Beyond that, one can create custom lenses and select which pre-defined
ones should be available. It is also possible to customize which widgets should
be available on the search results page.</p>
<p>Importantly, Kagi does not have search history, which I consider to be a good
privacy feature. To <a href="https://news.ycombinator.com/item?id=37561264">quote the founder of
Kagi</a>:</p>
<blockquote>
<p>Just to make it clear, Kagi does not link searches to an account already, to
begin with. Refer to our privacy policy. We simply do not need that data for
anything and it would be just a liability for us.</p>
</blockquote>
<p>That being said, Kagi does offer the option to customize search results by
selecting which pages to consider more important and which ones to ignore.
There’s even a <a href="https://kagi.com/stats?stat=leaderboard">ranking of search stats and website
popularity</a>.</p>
<p>And finally, if any of the above features does not work as expected, there’s
<a href="https://kagifeedback.org/">Kagi Feedback</a> that allows to report bugs and
suggest features. What I find impressive is that the founder of Kagi himself
often responds to bug reports.</p>
<h2 id="cons-to-be-aware-of">Cons to be aware of</h2>
<p>As already stated, I am very pleased with Kagi and I think it offers better
search results than other search engines I have tried so far. However, not all
search result from Kagi are good. For example, Kagi will sometimes point to
those weird generic pages that have paragraphs of text seemingly on the subject,
but not really having any real information. (Not all of those pages are
AI-generated, so perhaps that’s why they are difficult to filter out?)
Sometimes Kagi will include scam sites in the results, and sometimes it will
just not show you the obviously correct results. A great example of this is
searching for “youtube downloader”. <code>yt-dlp</code> is the result that you most likely
want, but instead you get a bunch of SEO spam. But even with that happening
occasionally, I still think the quality of Kagi search results is above its
competitors. I have not yet been in a situation where DDG or Google would find
a search result that Kagi couldn’t find.</p>
<p>One big problem with Kagi is using it as the default search engine. This is
tricky for two reasons. Firstly, Kagi is a paid service that requires one to be
logged in, which presents an obvious problem when browsing in private mode.
Secondly, certain browsers and OSes either only allow a certain set of
predefined search engines or require a lot of effort to add a new search engine.
Kagi’s <a href="https://news.ycombinator.com/item?id=41164462">team struggles to get around those
limitations</a>, but from the
perspective of a user, the whole experience can be frustrating. I use Firefox
on desktop and in order to have Kagi work in private mode I had to install an
extension. However, on mobile, I was unable to use Kagi at all. In mobile
Firefox it should be possible to add a new search engine with a custom search
URL, and Kagi provides a session link with a login token to make this work. For
some reason, this does not work on my phone, although the same exact method
works without problems on my wife’s phone. And then many mobile browsers, for
example Vivaldi, won’t even allow you to add a custom search engine. As a
result, I still have to use DuckDuckGo on my Android.</p>
<p>Another minor issue with Kagi is that it is clearly tailored for Americans. For
example, a comma is not recognized as a decimal separator in certain contexts.
If I search Kagi for “2.5USD in PLN” it activates a widget that gives me an
immediate response, but if I replace the dot with a comma and search for “2,5USD
in PLN” the widget does not work. This is minor and things are improving - it
used to be the case that a comma was not recognized at all as a decimal
separator, so asking Kagi for things like “2,5 * 2” would return a range “{2,5}”
instead of “5”.</p>
<p>Any map related searches are also far from being perfect, to say the least.
Kagi at least recognizes that and provides easy links to Google Maps and Apple
Maps from their map search. Long story short, every time I need to find local
information on the map, I revert to Google.</p>
<p>Lastly, image search returns essentially the same results as all the other
search engines, so there is really no difference here.</p>
<h2 id="summary">Summary</h2>
<p>For me, Kagi is one of the biggest discoveries of the past few years, and <strong>I
cannot afford not to use Kagi.</strong> It might not be perfect, but it has certainly
improved my web searching experience. Importantly, it has also given me hope
for a better web, one where the user’s needs are at the centre. I am curious to
see where the project goes, and in particular <a href="https://blog.kagi.com/dawn-new-era-search">how it aims to challenge Google’s
search monopoly</a>.</p>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr />
<ol>
<li id="fn1"><p>Quote comes from “The Anatomy of a Large-Scale Hypertextual Web Search
Engine” paper, from Appendix A titled “Advertising and Mixed Motives”.
Text of the paper available
<a href="http://infolab.stanford.edu/~backrub/google.html">here</a>.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>While writing this post, I also decided to test Bing. Not only the
results are garbage, but the results page is absolutely cluttered with
widgets and whatnot.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>My wife and I did some investigation of this, since the number of extra
searches felt surprisingly high. Turns out that the number is
artificially bumped, because switching to a tab that wasn’t active for a
while in a mobile browser will cause the page in that tab to be reloaded.
If you switch to a tab that contains Kagi search result, this reload will
trigger a new search of the previously searched term.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>Speaking of Kagi Assistant, I also think Kagi might have created <a href="https://www.youtube.com/watch?v=Lznc7p43nos">one of
the worst commercials ever</a>,
which is a real shame.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

        <p><a href="../blog.html">Back</a></p>
    </section>
</article>
]]></description>
    <pubDate>27/09/2024</pubDate>
    <guid>https://jstolarek.github.io/posts/2024-09-27-goodbye-google-switching-from-google-search-to-kagi.html</guid>
    <dc:creator>Jan Stolarek</dc:creator>
</item>
<item>
    <title>Four years of using a custom-built small form factor desktop PC</title>
    <link>https://jstolarek.github.io/posts/2024-08-27-four-years-of-using-a-custom-built-small-form-factor-desktop-pc.html</link>
    <description><![CDATA[<article>
    <section class="header">
        Posted on 27/08/2024
    </section>
    <section>
        <h1 id="four-years-of-using-a-custom-built-small-form-factor-desktop-pc">Four years of using a custom-built small form factor desktop PC</h1>
<p>For the past four years, I have been using a desktop PC I have custom-built to
my own needs. One of its key features is that it combines high-end computing
power with a small form factor (SFF). My motivation to write this post came
from a recent online discussion I participated in, where someone not familiar
with SFF PCs tried to convince me (and others) that SFF PCs are bound to
overheat. As a long-time user of an SFF PC, I can safely say this is not true
and it such <a href="https://en.wikipedia.org/wiki/Fear,_uncertainty,_and_doubt">FUD</a>
needs to be dismissed. I also want to share my experiences of building a small
form factor desktop PC, so that those of you interested in doing an SFF build
know where the challenges lie.</p>
<h2 id="a-bit-of-personal-history">A bit of personal history</h2>
<p>The last time I built a desktop PC was back in 2006. It was an Athlon 64-based
platform. A distinguishing feature of my build was the case. I went for a
Chieftec Dragon mid-tower, made of thick aluminium and weighing 8kg. I thought
of it as a once-in-a-lifetime investment, just like a Parker pen. I was not
entirely wrong. The case still serves for my mum’s PC, though the internals
have long been replaced.</p>
<p>In 2011, I rented a small studio flat and started living on my own. I no longer
had the space for a large desktop PC and have switched to using a laptop.
Compared to a desktop, usability was quite bad, but I appreciated the mobility.</p>
<p>In the second half of 2019 I was thinking of getting a new computer. The
release of Cyberpunk 2077 was approaching fast, and I was planning to get a
proper gaming PC just in time for the premiere. (It would also be the first
time in my life to even have a gaming PC.) I was also quite tired of having to
work on laptops - the ergonomics were proving to be very bad for my health. As
a quick stop-gap solution, towards the end of 2019, I bought an external
keyboard and a 23" LCD and used both with my laptop. Having worked with
them for a couple of days, it was settled: I am going back to having a proper
desktop PC. No more struggling with laptop ergonomics.</p>
<p>That was late 2019. In early 2020, COVID happened. Cyberpunk 2077 was delayed
a couple of months, initially to September. However, seeing how the pandemic
wreaks havoc in the electronic supply chains, in March I decided to proceed with
the plan of building a desktop PC. As you’ll see in a moment, it was already a
bit too late.</p>
<h2 id="deciding-on-a-small-form-factor-build">Deciding on a small form factor build</h2>
<p>When the <em>“small form factor”</em> term comes around, some of you might think of one
of the mini computers, such as the Intel NUC or HP Elite. That wouldn’t be
entirely wrong - these count as SFF desktops - but what I mean by SFF are small
desktop cases produced for PC enthusiasts. I was sold on the idea of a small
form factor PC by a friend of mine, who built his desktop in a <a href="https://www.dan-cases.com/dana4.php">Dan
A4-SFX</a>. It is one of the best SFF cases
on the market with dimensions of 20cm x 12cm x 32cm and just 7.2L of volume.
With such a small size, my friend just treats his computer as a portable PC for
game jams.</p>
<p>Don’t be fooled by the small dimensions. As you’ll see, these PCs can fit the
most powerful CPUs and GPUs. In fact, the best SFF cases are produced in small
numbers for enthusiasts who want to get the best possible performance, while
keeping their PC small.</p>
<p>From the beginning, <strong>I liked the idea of having a PC that’s actually small
enough to fit on my desk</strong>. I still had the memory of that huge Chieftec Dragon
case and how I struggled to fit it under the table. I’ve seen my friend’s PC in
action and envied how small it was. And so I decided to go with an SFF build.</p>
<p>I was planning on building a PC that is suitable for both gaming and work. For
gaming, I wanted an RTX card - these came to the market just a few months prior.
For work, I wanted a CPU with as many cores as possible. My major use case is
program compilation, and that’s when many cores definitely pay off.</p>
<h2 id="selecting-the-components">Selecting the components</h2>
<p>Having figured out my use cases and requirements, I was in for a lot of
research. One thing I quickly learned is that building a small form factor PC
is a bit like solving a puzzle. It is certainly an art of compromises, as one
cannot just put any components into the case.</p>
<p>The first choice to make was crucial: AMD or Intel? In the past, I had
experiences with both. While I still fondly remember my Xeon-based laptop, I
try not to take any sympathies with any of the companies and just pick the best
product. In 2020, it was certainly AMD, which made a spectacular comeback after
years of falling behind Intel. I decided to go for a Ryzen 9 3900X, a
12-core/24-thread CPU whose multiple cores would allow me to speed up my most
common use case - code compilation. Intel had practically nothing comparable to
offer, and getting an AMD was an obvious choice.</p>
<p>Once the platform was decided, it was time for the motherboard. The majority of
small form factor cases will only fit mini-ITX motherboards, which are 17cm by
17cm. These will have just one PCIe expansion slot and one pair of RAM
slots. Luckily, these are the only compromises one needs to make. Other than
that, mini-ITX boards can be as performant and feature-rich as their full-sized
ATX counterparts. I was planning to get a motherboard based on either B450 or
X470 chipset, but I was out of luck as all such motherboards have sold out by
April 2020, and it didn’t seem like they are coming back in stock anytime soon.
As an act of desperation, I had to get a <a href="https://rog.asus.com/motherboards/rog-crosshair/rog-crosshair-viii-impact-model">ROG Crosshair VIII
Impact</a>.
It is a high-end motherboard based on the X570 chipset, designed with
overlocking in mind. Unfortunately, for this reason it is quite expensive,
about a double of what I had originally intended to pay for a motherboard. As a
bonus problem, Crosshair VIII Impact has a mini-DTX format instead of mini-ITX.
This means an additional 3 centimetres in length, making it 20x17cm instead of
17x17cm, and impossible to fit in most SFF cases.</p>
<p>Luckily for me, by that time I have already decided on the <a href="https://ncased.com/products/m1-classic">NCase
M1</a>. With dimensions of 33cm x 16cm x
24cm and a total volume o 12.7 litres, it is larger than many SFF cases. It
also can fit a mini-DTX board. I remember my wife having serious doubts about
the M1 due to its price - it had to be imported from Taiwan, adding even further
to the costs - but once she saw how well the M1 is made and how modular it is,
she agreed it was absolutely worth the money.</p>
<p>Next, the power supply unit (PSU). SFF PCs typically use PSUs in the SFX
format, a smaller variant of the typical ATX format. Choosing a power supply
was a no-brainer - Corsair offers the best SFX power supplies on the market.
One really nice feature they have is modularity: cables that are not needed can
be disconnected from the power supply, instead of dangling inside the case.
Unfortunately, pandemic once again proved to be a pain. I was planning to get a
750W PSU, but the only one I could source was a 600W one. Luckily, 600 Watt was
enough for my build.</p>
<p>Finally, the graphics card. When it comes to building an SFF computer, <strong>GPU
compatibility is something that needs to be taken into account</strong>. Graphics
cards have got quite large these days, often taking as much as three expansion
slots and having three fans on the radiator. Many of the largest cards will not
fit into an SFF computer<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>. I had to take those limitations into account and
ultimately decided on the EVGA GeForce RTX 2070 Super Black Gaming<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>, a 2-fan
2-slot card that fits perfectly in the M1. Interestingly, I was able to get the
GPU just fine - major shortages didn’t happen until the second half of 2020.</p>
<p>Aside from that, I decided on 16GB of RAM memory (Corsair Vengence LPX) and
Seagate FireCuda 510 2TB NVMe drive.</p>
<h2 id="cooling">Cooling</h2>
<p>Figuring out the cooling is a whole separate subject. <strong>This is one thing that
needs to be done right with an SFF build.</strong></p>
<p>SFF cases tend to have quite strict limitations on CPU cooler height, though the
M1 is generous in that regard. After considering my options I decided on the
<a href="https://noctua.at/en/nh-u9s">Noctua NH-U9S</a> radiator with two 92mm
<a href="https://noctua.at/en/nf-a9-pwm">NF-A9</a> fans working as the exhaust. I also
mounted a 120mm intake fan on the side bracket. The plan was to have the side
fan pull air into the case, and the CPU fans exhaust it at the back. This was
the starting point, but it needs a few words of comment.</p>
<p>Firstly, having two fans on the cooler proved to be inconvenient when removing
the cooler from the CPU. I didn’t think this would be a problem since I wasn’t
planning to take off the cooler once the PC was assembled. However, I ended up
assembing and disassembling the computer several times. In the end I decided to
remove the rear fan from the CPU cooler and attach it to a dedicated place at
the back of the case. Cooling works essentially the same, but disassembling the
CPU cooler is now a lot easier.</p>
<p>Secondly, I’ve run into unexpected problems with the GPU. The graphics card I
picked had a semi-passive cooling, meaning the fans only turn on once the
temperature reaches 55C. This looks like a great idea on paper, but its
execution is flawed. It turns out that during regular desktop work card’s
temperature oscilates around the 55C mark, resulting in fans constantly turning
on and off. I probably wouldn’t have noticed if it wasn’t for a loud, audiable
click every time the fans start or stop, i.e. every 10 seconds. Sadly, the card
BIOS isn’t smart enough to spot such situations and just keep the fans on. A
solution was to mount extra fans underneath the card. M1 allows to mount two
fans at the bottom of the case, which I did. Of course, any extra fans under
the GPU defeat the purpose of passive cooling on the card.</p>
<p>Now, let’s talk about the fans. Last time I assembled a PC back in 2006 the
go-to brand when one wanted the best fans was Akasa. Indeed, they were great.
Quiet and extremely durable - the ones I got in 2006 still work without any
audiable buzz. Apparently, things have changed since then and in 2020 the brand
everyone recommends is Noctua. Because of that universal apprisal I decided to
go with Noctua fans. Unfortunatelly, despite good opinions, Noctua fans turned
out to be a major disappointment. I expect three qualities from a fan: it needs
to be effective, quiet, and durable. Noctua manages with the first and third
requirement, but not with the second one. I would expect that the only noise
comming from a fan is the hum of the air going through it. However, most of the
Noctua fans I bought emit a buzz and sometimes also vibrations (despite rubber
anti-vibration pads).</p>
<p>I initially started with five fans installed inside the case - two on the CPU,
two under the GPU, one on the side. Most of them would be faulty and buzz. I
went through several returns, RMAs, and experiments with different models
(Chromax, Redux). I had around a total of 10-12 Noctua fans go through my hands
before I finally found ones that weren’t buzzing. I also gave up on the idea of
two fans under the GPU. I couldn’t find the fifth fan that didn’t buzz and it
turned out that a single fan is enought to keep the GPU at 40C during standard
desktop work.</p>
<p>I admit that the four fans I settled on have been working fine for the past four
years without any problems, but the fact that majority of the fans I bought were
deffective is simply unacceptable. With such experience I can safely say that
<strong>Noctua fans are utter garbage and I don’t recommend them to anyone</strong>. I won’t
even mention the questionable colour choice Noctua has made with their fans -
luckily, there’s the Noctua Chromax line, which offers black fans.</p>
<p>Lastly, some people might want to consider liquid cooling. The NCase M1 is
designed for that, as are most SFF cases. The side bracket in the M1 allows to
mount a radiator with two 120mm fans, while at the back are two holes for those
wanting a custom liquid cooling loop connected to an external reservoir. The
reason why I didn’t go for water cooling was the uncertainty surrounding the
Linux support of water coolers. Back in 2020 there was no official Linux
software to control the water pumps. (Have things changed in 2024? Somehow, I
doubt it.) I didn’t want to end up with cooling that doesn’t work as intended
and decided to stick to the traditional air cooling.</p>
<h2 id="the-build">The build</h2>
<p>Here are some photos from the build process:</p>
<div class="thumbnail">
<figure>
<a href="/images/posts/2024-08-27-four-years-of-using-a-custom-built-small-form-factor-desktop-pc/component_test.jpg"><img src="/images/posts/2024-08-27-four-years-of-using-a-custom-built-small-form-factor-desktop-pc/component_test_thumbnail.jpg" /></a>
<figcaption>
Testing the components before installing them inside the case.
</figcaption>
</figure>
</div>
<div class="thumbnail">
<figure>
<a href="/images/posts/2024-08-27-four-years-of-using-a-custom-built-small-form-factor-desktop-pc/components_in_case.jpg"><img src="/images/posts/2024-08-27-four-years-of-using-a-custom-built-small-form-factor-desktop-pc/components_in_case_thumbnail.jpg" /></a>
<figcaption>
Putting components inside the case.
</figcaption>
</figure>
</div>
<div class="thumbnail">
<figure>
<a href="/images/posts/2024-08-27-four-years-of-using-a-custom-built-small-form-factor-desktop-pc/first_build_assembled.jpg"><img src="/images/posts/2024-08-27-four-years-of-using-a-custom-built-small-form-factor-desktop-pc/first_build_assembled_thumbnail.jpg" /></a>
<figcaption>
Side bracket with the intake cooling fan installed. Dust filters
and panels still missing. Note the power cable mess lying on the GPU and two
fans below the card.
</figcaption>
</figure>
</div>
<div class="thumbnail">
<figure>
<a href="/images/posts/2024-08-27-four-years-of-using-a-custom-built-small-form-factor-desktop-pc/top_view.jpg"><img src="/images/posts/2024-08-27-four-years-of-using-a-custom-built-small-form-factor-desktop-pc/top_view_thumbnail.jpg" /></a>
<figcaption>
Top view. Note the two fans attached to the CPU cooler.
</figcaption>
</figure>
</div>
<h2 id="temperatures">Temperatures</h2>
<p>The first thing I did after finishing the build was running the benchmarks, to
stress-test both the CPU (using <a href="https://www.mersenne.org/">Prime95</a>) and the
GPU (using <a href="https://geeks3d.com/furmark/">Furmark</a>). With CPU, I was able to
heat it up to about 90C, while benchmarking GPU yielded a 76C temperature.
However, these results differ from temperatures obtained during daily usage.</p>
<p>The CPU’s idle temperature was originally around 44-45C, though over the years
it would slightly rise to around 48-49C. I presume this is due to thermal paste
deterioration. During daily usage, I found it extremely difficult to heat the
CPU past the 70C mark, even if compiling on all cores for a longer period of
time. Note that I have disabled Core Performance Boost in the BIOS. Core
Performance Boost is like a factory CPU overlock. Disabling it results in
lowering the CPU voltage from 1.4V to 1.0V and thus lowering the idle
temperatures noticeably. This comes at a marginal loss of computing power,
which is something I am willing to accept for a noticeable reduction in power
consumption, thermals, and fan noise.</p>
<p>The GPU’s idle temperature with one fan underneath it typically sits at around
40C, with a power draw of about 20 Watts. These numbers are for Linux.
Interestingly, on Windows the GPU idle temperatures are closer to the 55C mark,
resulting in fans repeatedly going on and off. When playing games, the highest
temperature I got was 80C in Metro: Exodus. This is higher than in the
benchmarks, suggesting that Furmark might not be able to fully saturate the
card.</p>
<h2 id="upgrades">Upgrades</h2>
<p>One thing I always had at the back of my head when building a PC are the upgrade
options. From experience, I know it is quite difficult to predict the future
upgradability of the assembled configuration. That being said, for this
particular build things have gone well since I already upgraded the RAM, the CPU
and the GPU.</p>
<p>In early 2022, I upgraded the original 16GB of RAM to 32GB. This was motivated
by requirements of <a href="https://nixos.org/">Nix</a> and is something I intend to write
about on the blog. The tricky bit with this upgrade is that the DDR4 memory
these days comes in pairs of modules. However, small motherboards used in SFF
computers have only two RAM slots. As a result, it is not possible to simply
add more memory. Therefore, when upgrading RAM, I had to remove and replace
existing memory, which left me with a pair of unneeded memory modules that I had
to sell.</p>
<p>Earlier this year, I decided to upgrade both the CPU and the GPU. I swapped the
3900X with a Ryzen 9 5950X, which is a 16-core/32-thread CPU. The 5950X has the
same TDP (thermal design power = amount of emitted heat) as the old 3900X, which
means no modification to the existing cooling was needed. After the upgrade, I
noticed a decrease in CPU temperatures, but I don’t know whether this is due to
better thermal performance of the new CPU or just because of new thermal paste.</p>
<div class="thumbnail">
<figure>
<a href="/images/posts/2024-08-27-four-years-of-using-a-custom-built-small-form-factor-desktop-pc/cpu_replacement.jpg"><img src="/images/posts/2024-08-27-four-years-of-using-a-custom-built-small-form-factor-desktop-pc/cpu_replacement_thumbnail.jpg" /></a>
<figcaption>
Replacing the CPU.
</figcaption>
</figure>
</div>
<p>As for the GPU, I went for <a href="https://www.inno3d.com/product/inno3d-geforce-rtx-4070-super-twin-x2">Inno3D GeForce RTX 4070 Super Twin
X2</a>. I
built my PC in the first half of 2020, and in September of that year, nVidia
released the RTX 30xx series. The 30xx cards were noticeably larger and would
no longer fit the M1. I was concerned that I won’t be able to upgrade the GPU
without replacing the case, but luckily with the RTX 40xx series, nVidia has
done a great job at minimizing the cards. The new RTX 4070 Super is smaller and
draws roughly the same amount of power, while being several times more powerful
than the 2070 Super - <strong>I am truly impressed with what nVidia have achieved
here</strong>. At the same time, the 4070 Supers are quite affordable, certainly a lot
cheaper than what I paid for the 2070 Super in 2020. The only real downside is
the new GPU power connector, the infamous 12VHPWR, which is a major pain. It
lacks flexibility and getting the side panel to close after installing the new
card was a challenge.</p>
<p>I have also run into an unexpected compatibility issue between the new card and
the motherboard. The 4070 Super has a backplate and the card would not fit into
the PCIe slot due to collision with the cooling block at the back of the
motherboard. The solution was to remove one of the screws holding the backplate
- this resulted in an extra 0.5mm of space, which was enough to fit the new card.</p>
<div class="thumbnail">
<figure>
<a href="/images/posts/2024-08-27-four-years-of-using-a-custom-built-small-form-factor-desktop-pc/gpu_size_comparison.jpg"><img src="/images/posts/2024-08-27-four-years-of-using-a-custom-built-small-form-factor-desktop-pc/gpu_size_comparison_thumbnail.jpg" /></a>
<figcaption>
Size comparison between RTX 4070 Super (top) and RTX 2070 Super
(bottom). Notice the small PCB on the 4070 (top right).
</figcaption>
</figure>
</div>
<div class="thumbnail">
<figure>
<a href="/images/posts/2024-08-27-four-years-of-using-a-custom-built-small-form-factor-desktop-pc/side_view.jpg"><img src="/images/posts/2024-08-27-four-years-of-using-a-custom-built-small-form-factor-desktop-pc/side_view_thumbnail.jpg" /></a>
<figcaption>
After 4 years of usage. Note there is just one fan under the GPU
and the power cables have been properly organized. The side bracket is covered
with a dust filter.
</figcaption>
</figure>
</div>
<div class="thumbnail">
<figure>
<a href="/images/posts/2024-08-27-four-years-of-using-a-custom-built-small-form-factor-desktop-pc/side_view_no_bracket.jpg"><img src="/images/posts/2024-08-27-four-years-of-using-a-custom-built-small-form-factor-desktop-pc/side_view_no_bracket_thumbnail.jpg" /></a>
<figcaption>
Side bracket removed. The rear fan has been moved from the CPU
cooler to the back of the case.
</figcaption>
</figure>
</div>
<div class="thumbnail">
<figure>
<a href="/images/posts/2024-08-27-four-years-of-using-a-custom-built-small-form-factor-desktop-pc/gpu_replaced.jpg"><img src="/images/posts/2024-08-27-four-years-of-using-a-custom-built-small-form-factor-desktop-pc/gpu_replaced_thumbnail.jpg" /></a>
<figcaption>
4070 Super installed. The new 12VHPWR power connector is a major
pain: side panel barely fits, and cable management is again a bit of a mess.
</figcaption>
</figure>
</div>
<div class="thumbnail">
<figure>
<a href="/images/posts/2024-08-27-four-years-of-using-a-custom-built-small-form-factor-desktop-pc/tight_gpu_fit.jpg"><img src="/images/posts/2024-08-27-four-years-of-using-a-custom-built-small-form-factor-desktop-pc/tight_gpu_fit_thumbnail.jpg" /></a>
<figcaption>
There’s literally no space between the backplate of the 4070 Super
and the motherboard’s cooling block. Removing a screw was necessary to make the
card fit.
</figcaption>
</figure>
</div>
<h2 id="final-thoughts">Final thoughts</h2>
<p>After 4 years of using an SFF PC, I couldn’t be more happy with it. With a
16C/32T CPU and 32GB of RAM, it has all the computing power I need for work,
while a powerful GPU makes it also a high-end gaming PC. <strong>I never had any
problems with the temperatures, which are at a level comparable with a standard
PC. The single most important part of this success is the NCase M1.</strong> It is
small enough not to be a problem when standing on the desk. At the same time,
it has all the space needed to fit the components and provide them with proper
cooling. I am also very happy about the upgradability of the whole build.</p>
<p>This was my first SFF build, and it took a lot of research. I started thinking
about the new PC sometime in March 2020, and the build was ultimately finished
in July. Most of that time was spent waiting for a 750W power supply that never
arrived. Another 3 weeks went wasted because of the motherboard failure. The
one I originally got, died after a week. I had to disassemble the whole
computer, RMA the motherboard, wait for a replacement, and assemble everything
again.</p>
<p>Building a PC during the pandemic was also quite a challenge. I ended up
getting parts that I didn’t exactly want, but in the end I am not complaining.
The Crosshair VIII Impact motherboard proved to be a decent platform for future
upgrades, while the 600W power supply is, quite surprisingly, enough to power
both the new CPU and the new GPU.</p>
<p>The whole process of building my own SFF PC was greatly aided by the
<a href="https://www.youtube.com/@OptimumTech">OptimumTech channel on YouTube</a>. This is
a treasure trove of knowledge and I highly recommend you check it out if you
decide to make your own SFF build. Note that here I have only focused on my own
experiences and haven’t talked about SFF builds in general. In particular, I
haven’t even mentioned sandwich layouts, i.e. mounting the GPU parallel to the
motherboard using a riser cable, instead of inserting the GPU into a PCIe slot.
So, if you want to learn about that, OptimumTech’s channel is the place to go.</p>
<p>This post has got a lot longer than I initially intended. I plan to follow it
up with two more posts. One will be about the AMD’s AM4 platform and its
stability issues, while the other about being an early RTX adopter.</p>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr />
<ol>
<li id="fn1"><p>SFF cases have progressed noticeably since 2020 and are much better at
space management. For example, the successor of my M1 case, <a href="https://ncased.com/collections/m-series/products/m2-round">NCase
M2</a>, fits the
majority of GPUs on the market. Still, there are some large cards that it
will not fit.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>Sadly, in September 2022 <a href="https://www.tomshardware.com/news/evga-abandons-the-gpu-market-reportedly-citing-conflicts-with-nvidia">EVGA decided to withdraw from the GPU
market</a>,
the supposed reason being difficult partnership with nVidia.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

        <p><a href="../blog.html">Back</a></p>
    </section>
</article>
]]></description>
    <pubDate>27/08/2024</pubDate>
    <guid>https://jstolarek.github.io/posts/2024-08-27-four-years-of-using-a-custom-built-small-form-factor-desktop-pc.html</guid>
    <dc:creator>Jan Stolarek</dc:creator>
</item>
<item>
    <title>Fremen Zone&#58; Creating a Website Using Only HTML and CSS</title>
    <link>https://jstolarek.github.io/posts/2024-08-21-fremen-zone-creating-a-website-using-only-html-and-css.html</link>
    <description><![CDATA[<article>
    <section class="header">
        Posted on 21/08/2024
    </section>
    <section>
        <h1 id="fremen-zone-creating-a-website-using-only-html-and-css">Fremen Zone: Creating a Website Using Only HTML and CSS</h1>
<p>A year ago in July I wrote <a href="2023-07-12-all-the-things-ive-ever-done-wrong-with-my-websites.html">a post about all the websites that I have run in my
life</a>. An
important part of that list was Fremen Zone, a fansite dedicated to Frank
Herbert’s “Dune”. It was my first website ever, which I created back in high
school and have <a href="https://www.fremenzone.pl/legacy/index.htm">restored last year from backups on my hard
drive</a>. I ended the post with an
idea of creating a new version of Fremen Zone:</p>
<blockquote>
<p>Restoring the Fremen Zone back to life sparked a new desire in me. While I
said I have no intention of updating it, I feel like re-doing the whole site
from scratch. (…) And so I am slowly gathering material for a new Dune
fanpage. All the lessons above have taught me to avoid complexity and stay as
close to the basics as possible. And so my plan is to create a new website
based on pure HTML and CSS.</p>
</blockquote>
<p>Since late June 2023 I have been hard at work to create a new version of Fremen
Zone. The website went live on February 1st 2024 and is available at
<a href="https://www.fremenzone.pl" class="uri">https://www.fremenzone.pl</a>. In this post I want to talk about the technical
aspects of the new Fremen Zone page, in particular putting emphasis on
simplicity and developing a dedicated static page generator.</p>
<p>Now, one tiny detail before we move on. If you clicked on the link below, you
already noticed that Fremen Zone is in Polish, not English. Google Translate
does a decent job at translating it to English, but make sure to fold the
translation bar. Otherwise it covers the top navigation bar.</p>
<h2 id="keeping-things-simple">Keeping things simple</h2>
<p>The primary principle driving the technical design of the new page was to keep
technical solutions as simple as possible. I didn’t want to rely on any
existing frameworks, content management systems, or anything of that sort.
Instead, I wanted to create a website that uses only HTML5 and CSS, with no
JavaScript. The goal was to make a page that is static, small (=quick to load),
fast and responsive, without bloat, and also easy to deploy or move to a
different hosting.</p>
<p>The first step was layout design. The old Fremen Zone used frames, which nobody
really relies on today. For the new version, I decided to go with a navigation
menu placed at the top of the page. This layout looks clean and minimalistic,
which is one of the things I wanted to achieve with the new website.</p>
<div class="thumbnail">
<figure>
<a href="/images/posts/2024-08-21-fremen-zone-creating-a-website-using-only-html-and-css/navbar.png"><img src="/images/posts/2024-08-21-fremen-zone-creating-a-website-using-only-html-and-css/navbar_thumbnail.png" /></a>
<figcaption>
The navigation bar highlights the current section. Below the navbar is a section logo.
</figcaption>
</figure>
</div>
<p>I haven’t done any front-end programming since my original work on Fremen Zone
nearly quarter a century ago, so not only have I forgotten everything I learned
about HTML and CSS back then, but also both standards have evolved over time.
And so I was learning HTML5 and CSS from scratch as I worked on the new page
design. An important change made to HTML since its early days is the
introduction of tags that carry important semantic meaning. And so the
navigation bar is enclosed in <code>&lt;nav&gt;&lt;/nav&gt;</code> tags, sub-page headers use
<code>&lt;header&gt;&lt;/header&gt;</code> tag, and so on – whenever semantic tags were available I
made sure to use them, though I didn’t get everything right on first attempt.
More on that in a moment.</p>
<h2 id="browser-compatibility">Browser compatibility</h2>
<p>One of my top technical priorities was browser compatibility. I wanted to make
sure that the website will work as intended, no matter the browser. This is
something I have put a lot of attention to when designing the original Fremen
Zone two decades ago. The difference is that back then I tested the page with
Internet Explorer and Netscape Navigator, while now the tested browsers included
Firefox (that’s my default browser), Chromium (I avoid Chrome like a plague, but
acknowledge the fact that most people use it), <a href="https://www.palemoon.org/">Pale
Moon</a>
(pre-<a href="https://blog.mozilla.org/en/mozilla/introducing-firefox-quantum/">Quantum</a>
fork of Firefox), <a href="http://links.twibright.com/">links</a> and
<a href="https://lynx.invisible-island.net/">lynx</a> (terminal-based text-only web
browsers), <a href="https://dillo-browser.github.io/">Dillo</a> (an extremely minimalistic
web browser), and <a href="https://www.torproject.org/">Tor</a> (privacy-focused web
browser based on Firefox). Despite the multitude of modern browsers, the task
was generally easier than 25 years ago.</p>
<div class="thumbnail">
<figure>
<a href="/images/posts/2024-08-21-fremen-zone-creating-a-website-using-only-html-and-css/firefox.png"><img src="/images/posts/2024-08-21-fremen-zone-creating-a-website-using-only-html-and-css/firefox_thumbnail.png" /></a>
<figcaption>
Intended page rendering in Firefox.
</figcaption>
</figure>
</div>
<p>The new version of Fremen Zone renders as intended in Firefox, Chromium and Pale
Moon. However, the more obscure browsers don’t always render the page as
intended. For example, Dillo does not correctly handle CSS margins and width
attributes, resulting, among others, in misaligned section logo images and
incorrect text width:</p>
<div class="thumbnail">
<figure>
<a href="/images/posts/2024-08-21-fremen-zone-creating-a-website-using-only-html-and-css/dillo.png"><img src="/images/posts/2024-08-21-fremen-zone-creating-a-website-using-only-html-and-css/dillo_thumbnail.png" /></a>
<figcaption>
Dillo does not handle text flow as intended. As a bonus, the
background of the main page logo has the wrong colour.
</figcaption>
</figure>
</div>
<p>Tor on the other hand, as part of its security measures, blocks web fonts. This
results in incorrect rendering of the RSS icon on the right of the navigation
bar (see <a href="#polishing-the-details">Polishing the details</a> section below for more
details on web fonts).</p>
<p>It was a fun exercise to get the page to look readable in text-based web
browsers. These browsers are obviously quite limited at what they can do, but
one thing they forced me to get right was correct semantic usage of HTML tags.
For example, I first started out with using stylized <code>&lt;div&gt;</code> tags for the
headers and sub-headers on the page. This looked as intended in graphical
browsers, but in text-based ones the headers rendered as a one-line paragraphs
of text and were indistinguishable from normal paragraphs. The solution was to
switch to dedicated header tags, <code>&lt;h1&gt;</code> and <code>&lt;h2&gt;</code>. In graphical browsers this
makes no difference since the styling is handled with CSS. However, text-based
browsers now interpret headers correctly and make them stand out from the rest
of the text.</p>
<div class="thumbnail">
<figure>
<a href="/images/posts/2024-08-21-fremen-zone-creating-a-website-using-only-html-and-css/lynx.png"><img src="/images/posts/2024-08-21-fremen-zone-creating-a-website-using-only-html-and-css/lynx_thumbnail.png" /></a>
<figcaption>
Fremen Zone rendering in Lynx. Note the repeated navbar.
</figcaption>
</figure>
</div>
<p>I also wanted Fremen Zone to display correctly on mobile devices. In principle,
I don’t really care much about smartphones - I consider them a horrible way of
interacting with the Internet and rarely use mine to browse the web. But at the
same time, I thought of this as in interesting technical challenge and a
learning opportunity.</p>
<p>The biggest problem to overcome with rendering Fremen Zone on mobile was the
navigation bar. Firstly, the navbar is structured differently on desktop and on
mobile, forcing two copies of it to be defined in the source code. At any given
time, only one of those copies is visible, which is controlled by the <code>@media</code>
at-rules in CSS. Text-based browsers don’t handle <code>@media</code> at-rules as intended
and display both copies of the menu at the same time. Hence, the repeated
navbar in the screenshot above.</p>
<p>The mobile version of the navigation bar, instead of a list of available page
sections, contains only a “hamburger menu” icon. The proper menu becomes
visible once the icon is clicked. Sadly, getting this behaviour to work
requires a short JavaScript snippet attached via the <code>&lt;a&gt;</code> tag’s <code>onclick</code>
property. It isn’t a long script, just a few lines of code to add or remove a
CSS class that switches menu visibility, but it means that my goal of creating a
website that does not use JavaScript at all was not possible to achieve. Not
without giving up on mobile responsiveness, at least. I spent hours
experimenting with different approaches, hoping I can get things to work with
just CSS, but to no avail. I accepted that I need these few lines of JavaScript
and moved on.</p>
<p>Finally, there was the question of compatibility with various mobile browsers.
Luckily, things went much smoother than on desktop. Essentially all browsers I
tested - Firefox, DuckDuckGo, Vivaldi, Opera Mini, Edge - rendered the page as
intended.</p>
<h2 id="writing-a-custom-website-generator">Writing a custom website generator</h2>
<p>I spent approximately two weeks prototyping the layout. Once the initial design
was in place I began preliminary work on the contents. After creating several
subpages it quickly became apparent that pages contain lots of repetition, in
particular in the <code>&lt;head&gt;</code> and <code>&lt;navbar&gt;</code> tags. Surely, there were minor
differences - each page had a different <code>&lt;title&gt;</code> and each subpage’s navbar
highlighted a different current section - but the overall structure of each page
was identical. It was clear at this point that this repetition must be
eliminated. And so the next step was to write a custom static website
generator.</p>
<p>I decided to put each logical fragment of the page into a separate template
file. For example, template for the page’s HTML header contains:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode html"><code class="sourceCode html"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="dt">&lt;</span><span class="kw">head</span><span class="dt">&gt;</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">&lt;</span><span class="kw">meta</span><span class="ot"> charset</span><span class="op">=</span><span class="st">&quot;utf-8&quot;</span><span class="dt">&gt;</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">&lt;</span><span class="kw">meta</span><span class="ot"> name</span><span class="op">=</span><span class="st">&quot;viewport&quot;</span><span class="ot"> content</span><span class="op">=</span><span class="st">&quot;width=device-width, initial-scale=1.0&quot;</span><span class="dt">&gt;</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>  <span class="dt">&lt;</span><span class="kw">meta</span><span class="ot"> name</span><span class="op">=</span><span class="st">&quot;author&quot;</span><span class="ot"> content</span><span class="op">=</span><span class="st">&quot;Jan Stolarek&quot;</span><span class="dt">&gt;</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>  <span class="dt">&lt;</span><span class="kw">link</span><span class="ot"> rel</span><span class="op">=</span><span class="st">&quot;preload&quot;</span><span class="ot"> as</span><span class="op">=</span><span class="st">&quot;font&quot;</span><span class="ot"> type</span><span class="op">=</span><span class="st">&quot;font/woff2&quot;</span><span class="ot"> href</span><span class="op">=</span><span class="st">&quot;RELPATH/fonts/fa-solid-900.woff2&quot;</span><span class="ot"> crossorigin</span><span class="dt">&gt;</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>  <span class="dt">&lt;</span><span class="kw">link</span><span class="ot"> rel</span><span class="op">=</span><span class="st">&quot;preload&quot;</span><span class="ot"> as</span><span class="op">=</span><span class="st">&quot;style&quot;</span><span class="ot"> type</span><span class="op">=</span><span class="st">&quot;text/css&quot;</span><span class="ot"> href</span><span class="op">=</span><span class="st">&quot;RELPATH/styl.css&quot;</span><span class="dt">&gt;</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>  <span class="dt">&lt;</span><span class="kw">link</span><span class="ot"> rel</span><span class="op">=</span><span class="st">&quot;preload&quot;</span><span class="ot"> as</span><span class="op">=</span><span class="st">&quot;image&quot;</span><span class="ot"> type</span><span class="op">=</span><span class="st">&quot;image/png&quot;</span><span class="ot"> href</span><span class="op">=</span><span class="st">&quot;RELPATH/img/SECTION.png&quot;</span><span class="dt">&gt;</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>  <span class="dt">&lt;</span><span class="kw">link</span><span class="ot"> rel</span><span class="op">=</span><span class="st">&quot;stylesheet&quot;</span><span class="ot"> type</span><span class="op">=</span><span class="st">&quot;text/css&quot;</span><span class="ot"> href</span><span class="op">=</span><span class="st">&quot;RELPATH/styl.css&quot;</span><span class="dt">&gt;</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>  <span class="dt">&lt;</span><span class="kw">link</span><span class="ot"> rel</span><span class="op">=</span><span class="st">&quot;icon&quot;</span><span class="ot"> type</span><span class="op">=</span><span class="st">&quot;image/x-icon&quot;</span><span class="ot"> href</span><span class="op">=</span><span class="st">&quot;RELPATH/favicon.png&quot;</span><span class="dt">&gt;</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>  <span class="dt">&lt;</span><span class="kw">link</span><span class="ot"> rel</span><span class="op">=</span><span class="st">&quot;license&quot;</span><span class="ot"> href</span><span class="op">=</span><span class="st">&quot;RELPATH/LICENCJA.md&quot;</span><span class="dt">&gt;</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>  <span class="dt">&lt;</span><span class="kw">title</span><span class="dt">&gt;</span>PAGETITLE<span class="dt">&lt;/</span><span class="kw">title</span><span class="dt">&gt;</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="dt">&lt;/</span><span class="kw">head</span><span class="dt">&gt;</span></span></code></pre></div>
<p>Putting all those repeating fragments into their own template files allowed me
to reduce each page to just its proper contents enclosed inside a <code>&lt;div&gt;&lt;/div&gt;</code>
block. Everything else - <code>&lt;head&gt;</code>, <code>&lt;navbar&gt;</code>, <code>&lt;header&gt;</code>, <code>&lt;footer&gt;</code>, etc. -
is stored in template files. This way all the repetition in HTML sources is
gone and changing, say, page’s <code>&lt;head&gt;</code> section requires modifying only the
respective template file.</p>
<p>I then wrote a bash script to assemble full HTML pages from templates and the
proper source files. At the heart of the script are the following lines:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="bu">echo</span> <span class="st">&quot;&lt;!DOCTYPE html&gt;&quot;</span>        <span class="op">&gt;</span>  <span class="va">$HTMLFILE</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="bu">echo</span> <span class="st">&quot;&quot;</span>                       <span class="op">&gt;&gt;</span> <span class="va">$HTMLFILE</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="bu">echo</span> <span class="st">&quot;&lt;html lang=</span><span class="dt">\&quot;</span><span class="st">pl</span><span class="dt">\&quot;</span><span class="st">&gt;&quot;</span>     <span class="op">&gt;&gt;</span> <span class="va">$HTMLFILE</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span> <span class="va">$TEMPLATEDIR</span>/head.html    <span class="op">&gt;&gt;</span> <span class="va">$HTMLFILE</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="bu">echo</span> <span class="st">&quot;&quot;</span>                       <span class="op">&gt;&gt;</span> <span class="va">$HTMLFILE</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="bu">echo</span> <span class="st">&quot;&lt;body&gt;&quot;</span>                 <span class="op">&gt;&gt;</span> <span class="va">$HTMLFILE</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="bu">echo</span> <span class="st">&quot;&quot;</span>                       <span class="op">&gt;&gt;</span> <span class="va">$HTMLFILE</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span> <span class="va">$TEMPLATEDIR</span>/scripts.html <span class="op">&gt;&gt;</span> <span class="va">$HTMLFILE</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="bu">echo</span> <span class="st">&quot;&quot;</span>                       <span class="op">&gt;&gt;</span> <span class="va">$HTMLFILE</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span> <span class="va">$TEMPLATEDIR</span>/navbar.html  <span class="op">&gt;&gt;</span> <span class="va">$HTMLFILE</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="bu">echo</span> <span class="st">&quot;&quot;</span>                       <span class="op">&gt;&gt;</span> <span class="va">$HTMLFILE</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span> <span class="va">$TEMPLATEDIR</span>/header.html  <span class="op">&gt;&gt;</span> <span class="va">$HTMLFILE</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="bu">echo</span> <span class="st">&quot;&quot;</span>                       <span class="op">&gt;&gt;</span> <span class="va">$HTMLFILE</span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a><span class="bu">echo</span> <span class="st">&quot;&lt;main&gt;&quot;</span>                 <span class="op">&gt;&gt;</span> <span class="va">$HTMLFILE</span></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a><span class="bu">echo</span> <span class="st">&quot;&quot;</span>                       <span class="op">&gt;&gt;</span> <span class="va">$HTMLFILE</span></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span> <span class="va">$SRCDIR</span>/<span class="va">$FILEPATH</span>         <span class="op">&gt;&gt;</span> <span class="va">$HTMLFILE</span></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a><span class="bu">echo</span> <span class="st">&quot;&quot;</span>                       <span class="op">&gt;&gt;</span> <span class="va">$HTMLFILE</span></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a><span class="bu">echo</span> <span class="st">&quot;&lt;/main&gt;&quot;</span>                <span class="op">&gt;&gt;</span> <span class="va">$HTMLFILE</span></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a><span class="bu">echo</span> <span class="st">&quot;&quot;</span>                       <span class="op">&gt;&gt;</span> <span class="va">$HTMLFILE</span></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span> <span class="va">$TEMPLATEDIR</span>/footer.html  <span class="op">&gt;&gt;</span> <span class="va">$HTMLFILE</span></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a><span class="bu">echo</span> <span class="st">&quot;&quot;</span>                       <span class="op">&gt;&gt;</span> <span class="va">$HTMLFILE</span></span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a><span class="bu">echo</span> <span class="st">&quot;&lt;/body&gt;&quot;</span>                <span class="op">&gt;&gt;</span> <span class="va">$HTMLFILE</span></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a><span class="bu">echo</span> <span class="st">&quot;&lt;/html&gt;&quot;</span>                <span class="op">&gt;&gt;</span> <span class="va">$HTMLFILE</span></span></code></pre></div>
<p>There are some bash variables in here, but their names should be
self-descriptive.</p>
<p>You might be wondering about the <code>RELPATH</code>, <code>SECTION</code>, and <code>PAGETITLE</code> words
used in the example template file above. These are reserved words that are
replaced with page-specific values using <code>sed</code>. This allows not only to have
page-specific titles and section logos, but also calculate relative paths:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Insert relative paths</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="bu">[</span> <span class="st">&quot;</span><span class="va">$FILEDIR</span><span class="st">&quot;</span> <span class="ot">=</span> <span class="st">&quot;.&quot;</span> <span class="bu">]</span><span class="kw">;</span> <span class="cf">then</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>    <span class="va">RELPATH</span><span class="op">=</span><span class="st">&quot;.&quot;</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>    <span class="va">SLASHES</span><span class="op">=</span><span class="st">&quot;</span><span class="va">${FILEDIR</span><span class="op">//</span><span class="ss">[^</span><span class="dt">\/</span><span class="ss">]</span><span class="va">}</span><span class="st">&quot;</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>    <span class="va">DIRDEPTH</span><span class="op">=</span><span class="st">&quot;</span><span class="va">${</span><span class="op">#</span><span class="va">SLASHES}</span><span class="st">&quot;</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    <span class="va">RELPATH</span><span class="op">=</span><span class="st">&quot;..&quot;</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="va">$(</span><span class="fu">seq</span> 1 <span class="va">$DIRDEPTH)</span><span class="kw">;</span> <span class="cf">do</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">RELPATH</span><span class="op">=</span><span class="va">$RELPATH</span><span class="st">&quot;/..&quot;</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">done</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a><span class="cf">fi</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="fu">sed</span> <span class="at">--in-place</span> <span class="st">&quot;s,RELPATH,</span><span class="va">$RELPATH</span><span class="st">,g&quot;</span> <span class="st">&quot;</span><span class="va">$HTMLFILE</span><span class="st">&quot;</span></span></code></pre></div>
<p>or insert last modification date from <code>git</code>:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Add last modification date</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="va">LASTMODIFIED</span><span class="op">=</span><span class="kw">`</span><span class="fu">git</span> log <span class="at">-1</span> <span class="at">--pretty</span><span class="op">=</span><span class="st">&quot;format:%cs&quot;</span> <span class="va">$SRCDIR</span>/<span class="va">$FILEPATH</span><span class="kw">`</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="fu">sed</span> <span class="at">--in-place</span> <span class="st">&quot;s,LASTMODIFIED,</span><span class="va">$LASTMODIFIED</span><span class="st">,g&quot;</span> <span class="st">&quot;</span><span class="va">$HTMLFILE</span><span class="st">&quot;</span></span></code></pre></div>
<p>I like to keep all my projects organized, and so files that comprise the website
are placed into dedicated directories. For example, all images are placed in
<code>img</code> directory, while all kinds of resources (e.g. web fonts, a unique
non-generated 404 page, favicon) are in the <code>res</code> folder:</p>
<pre><code>fremenzone
├── css
├── docs
├── img
├── res
├── src
└── templates</code></pre>
<p>In order for all these files to form a coherent page that can be displayed in a
browser, they must be assembled into one directory - <code>docs</code>. This was initially
done by the same bash script that generated the pages from templates. The
script would first copy all images, resources and CSS files to <code>docs</code>, and then
it would proceed to generate <em>all</em> HTML pages, regardless of whether they were
changed or not.</p>
<p>This approach was very easy to program and worked well at first. However, as I
added more subpages, the approach of rebuilding every HTML page became a bit too
slow. Obviously, it wasn’t very slow, but slow enough that I had to
deliberately pause before pressing F5 in the browser after making changes to the
sources. It was time to write a proper <code>Makefile</code> for the page.</p>
<p>With a <code>Makefile</code> in place, only the modified files are regenerated. No more
rebuilding of all the HTML sources or copying of the whole image directory.
Switching the build process to <code>make</code> made rebuilding the modified sources two
orders of magnitude faster. The caveat is that rebuilding the whole website,
for example after calling <code>make clean</code>, is actually several times slower than
with the bash script. However, that is a corner case that happens very rarely.
What matters is that the most common use case has been optimized.</p>
<h2 id="polishing-the-details">Polishing the details</h2>
<p>At various moments during Fremen Zone development, I’ve spent quite significant
amounts of time on getting the various details right.</p>
<h3 id="html-validation">HTML validation</h3>
<p>First and foremost, I wanted to ensure that I write correct HTML. To this end,
I wrote a bash script that checks all the generated pages using
<a href="https://www.html-tidy.org/">html-tidy</a>, and created a dedicated <code>make</code> target
to be able to call it easily. The next step was to set up a GitHub action that
calls the script on every commit, just in case I miss something during local
development. Additionally, just to be extra sure, I’ve set up a <a href="https://github.com/Cyb3r-Jak3/html5validator-action">GitHub
action</a> that checks
generated pages using
<a href="https://github.com/svenkreiss/html5validator">html5validator</a>.</p>
<h3 id="rss-feed">RSS feed</h3>
<p>One of the things I absolutely wanted to have on my page was an RSS feed.
Again, I didn’t want to rely on any generators - this might not have even been
possible, given that Fremen Zone does not take a format of a blog - which forced
me to dive into <a href="https://cyber.harvard.edu/rss/rss.html">RSS specification</a>.
Luckily, it’s not that complex, but it took some effort to make things work as
intended. Not everything was clear from the specification, forcing me to peek
into various generated feeds, such as the one generated by Hakyll for this blog.
I also mixed in elements of
<a href="https://validator.w3.org/feed/docs/atom.html">Atom</a>, so the feed isn’t purely
in the RSS format.</p>
<h3 id="web-fonts">Web fonts</h3>
<p>Once an RSS feed was ready, I wanted to have an RSS icon in the navigation bar.
This was surprisingly tricky to get right. After quite a substantial amount of
research and experimentation, I figured out that the only reliable method that
works on multiple different browsers is to use a dedicated glyph from an
embedded web font. I went with an older version (5.15.4) of
<a href="https://github.com/FortAwesome/Font-Awesome/">FontAwesome</a> web fonts in two
different formats, <a href="https://caniuse.com/woff">woff</a> and
<a href="https://caniuse.com/woff2">woff2</a>, the former one for those poor souls that use
unbelievably outdated web browsers. Using a web font also solved the problem of
displaying an icon for “hamburger menu” on mobile devices.</p>
<h3 id="optimizing-loading-times">Optimizing loading times</h3>
<p>At some point, I spent quite a significant amount of time on figuring out how to
optimize Fremen Zone for faster loading. I admit that I am a beginner when it
comes to the topic and I had to rely on pieces of advice found online - often
conflicting, forcing me to dive deeper into HTML5 specification and browser
documentation. One simple thing was to use a CSS minifier, a program that
strips whitespaces and comments from a CSS file, making it more than 50%
smaller. I also experimented with HTML minifiers, but couldn’t find one that
would actually work without breaking the page and violating the HTML5 standard.</p>
<p>The next step in optimizing the loading times was related to embedded web fonts.
Firstly, it is possible to strip the redundant glyphs from a font file. I only
needed two glyphs from each of the two font files (woff, woff2), which allowed
me to reduce file sizes from 40-50kB, to less than a kilobyte. Secondly, it is
possible to preload the web fonts, i.e. instruct the browser in the HTML header
to start loading the font files before the rest of the page is parsed and the
glyphs from the font are actually requested. It is also possible to preload the
CSS and other resources, which I did. I’m not exactly sure whether this has any
benefits - the measurements I made using the browser’s developer tools were
inconclusive. However, there seems to be no costs of attempting a preload, so I
decided to keep it. For a brief moment I also experimented with <a href="https://developer.mozilla.org/en-US/docs/Web/Performance/Lazy_loading">lazy image
loading</a>,
but realized that’s one of the features I absolutely hate on the web and dropped
the whole idea.</p>
<h3 id="improving-accessibility-with-alt-attributes">Improving accessibility with <code>alt</code> attributes</h3>
<p>When I set up the HTML validators, I got a bunch of warnings about missing <code>alt</code>
attributes for the <code>&lt;img&gt;</code> tags. This turned out to be another rabbit hole, as
I spent several hours trying to understand what <code>alt</code> attribute should contain.
And then I spent even more time writing the contents of those attributes. Long
story short, <code>alt</code> attribute should describe the contents of an image. Just
imagine someone asking you “what’s in this picture?” and you go to describe what
the image depicts. In the future, I’d like to learn more about making a web page
accessible for people using screen readers. Providing meaningful <code>alt</code> tags is
a small first step towards that goal.</p>
<h2 id="hosting-the-site">Hosting the site</h2>
<p>I don’t expect Fremen Zone to generate large traffic, and so for the time being
I decided GitHub Pages should suffice as a hosting provider. There was a small
catch, though. GitHub Pages can only host websites available in a public
repository, at least on the free plan. However, I didn’t want to expose any of
the in-progress work, notes, etc. The solution was handed to my by a colleague
from work and is in fact trivial: use two repositories, a private one for
development and a public one for hosting. For this reason, if you go to <a href="https://github.com/jstolarek/fremenzone">Fremen
Zone repository</a> you will only find the
generated HTML files, LICENSE and README files as well as definitions of GitHub
workflows. All the scripts discussed in this post are in the private repo.</p>
<p>To make updating of the public repository easier I created another dedicated
script that performs a bunch of safety checks (no untracked files, no
uncommitted changes, no unaddressed TODOs, etc.), and, if those pass, builds the
page from sources and copies the resulting files to the public repository. I
then need to manually commit and push the changes, which is another safety
measure against publishing something unintended.</p>
<h2 id="summary">Summary</h2>
<p>Front-end development is definitely not my cup of tee, but creating a website
from scratch using only HTML and CSS was actually quite a lot of fun. By
relying on the most basic technologies, I expect the site to be future-proof and
easy to move to different hosting, once such a need arises.</p>

        <p><a href="../blog.html">Back</a></p>
    </section>
</article>
]]></description>
    <pubDate>21/08/2024</pubDate>
    <guid>https://jstolarek.github.io/posts/2024-08-21-fremen-zone-creating-a-website-using-only-html-and-css.html</guid>
    <dc:creator>Jan Stolarek</dc:creator>
</item>

    </channel>
</rss>
